{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 숫자 인식 연습\n",
    "'''\n",
    "이미 학습된 매개변수를 사용하여 학습 과정은 생략하고, 추론 과정만 구현한다.\n",
    "이 추론 과정을 신경망의 순전파forward propagation라고도 한다.\n",
    "*기계학습과 마찬가지로, 신경망도 두 단계를 거쳐 학습한다. 1.훈련데이터(학습데이터)를 이용해 가중치 매개변수를 학습하고, 2.추론 단계에서 앞에서 얻은 매개변수를 이용하여 입력데이터를 분류한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 셋(손글씨 숫자 이미지 집합) 이용\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 최초의 데이터 수집에는 조금 시간이 걸린다.\n",
    "(x_train, t_train), (x_test, t_test) = \\ # (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
    "    load_mnist(flatten=True, normalize=False) # flatten : 입력 이미지를 1차원 배열로 만들것인지 여부, normalize : 입력 이미지의 픽셀 값을 0.0 ~ 1.0 사이로 정규화 할 것인지 여부\n",
    "# 사용되지 않았지만, one_hot_lable 옵션은 레이블을 하나의 정답(1,hot)과 나머지 오답(0) 형식으로 만들것인지 여부를 결정한다.\n",
    "\n",
    "# 각 데이터의 형상 출력\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000,)\n",
    "print(x_test.shape) # (10000, 784)\n",
    "print(t_test.shape) # (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image # PIL : Python Image Library\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img)) # numpy로 저장된 이미지 데이터를 PIL용 데이터 객체로 변환한다.\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label) # 5\n",
    "\n",
    "print(img.shape) # (784,) 현재 이미지는 1차원 numpy 배열 형태로 저장되어있다.\n",
    "img = img.reshape(28,28) # 원래 이미지 모양으로 변경 (원래 형상 크기 28*28=784), reshape 메서드를 통해 numpy 배열의 형샹을 바꿀 수 있다.\n",
    "print(img.shape) # (28,28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 데이터 수집 함수\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "        load_mnist(normalize=False, flatten=True, one_hot_label=False)\n",
    "    return x_test,t_test\n",
    "\n",
    "# 네트워크 초기화 함수\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f: # sample_weight는 학습된 가중치 매개변수가 담겨있는 파일이다. 가중치와 편향 매개변수가 딕셔너리로 저장되어 있다.\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    return network\n",
    "\n",
    "##### 활성화 함수 start #####\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "##### 활성화 함수 end #####\n",
    "\n",
    "# 추론 함수\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seongik/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9207\n"
     ]
    }
   ],
   "source": [
    "# 함수 이용해 mnist 분류 신경망 구현\n",
    "\n",
    "x, t = get_data() # 데이터셋 수집\n",
    "network = init_network() # 네트워크 생성\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)): # for문을 돌며 x에 저장된 이미지 데이터를 1장씩 꺼내어 predict() 함수로 분류\n",
    "    y = predict(network, x[i]) # predict함수는 각 레이블의 확률을 numpy 배열로 반환\n",
    "    p= np.argmax(y)  # argmax 함수는 이 배열에서 값이 가장 큰(즉, 확률이 가장 높은) 원소의 인덱스를 반환\n",
    "    if p == t[i]: # 만약 신경망이 예측한 답변(p)와 정답 레이블(t[i])이 같다면(즉, 맞췄다면)\n",
    "        accuracy_cnt += 1 # 맞힌 숫자를 센다.\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) # (맞힌 숫자 / 전체 이미지)로 정확도를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_mnist 함수의 normalize = True옵션은 0~255의 픽셀값을 0.0~1.0 범위로 변환한다.\n",
    "# 이처럼 데이터를 특정 범위로 변환하는 것을 정규화normalization이라고 하고, 신경망의 입력 데이터에 특정 변환을 가하는 것을 전처리pre-processing라고 한다.\n",
    "\n",
    "# 현업에서도 신경망(딥러닝)에 전처리를 활발히 사용한다.\n",
    "# 현업에서는 데이터 전체의 분포를 고려해 전처리 하는 경우가 많다.\n",
    "# 예를 들어, 데이터 전체 평균과 표준 편차를 이용하여 데이터들이 0을 중심으로 분포하도록 이동하거나, 데이터의 확산 범위를 제약하는 정규화를 수행한다.\n",
    "# 그 외에도, 전체 데이터를 균일하게 분포시키는 데이터 백색화whitening 등도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n",
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터와 가중치 매개변수의 '형상'에 주목해보자.\n",
    "\n",
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print(x.shape) # (10000,784)\n",
    "print(x[0].shape) # (784,)\n",
    "print(W1.shape) # (784,50)\n",
    "print(W2.shape) # (50,100)\n",
    "print(W3.shape) # (100,10) 최종적으로는 0~9까지의 10개 숫자로 분류된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 이미지 100개를 한 묶음으로 만들어 predict 함수에 한번에 넘긴다면 (x의 형상 : 100 * 784)\n",
    "# 100장 분량의 입력 데이터 결과가 한 번에 출력된다.\n",
    "# 이처럼 하나로 묶은 입력 데이터를 배치batch라고 한다.\n",
    "\n",
    "# 배치가 가지는 이점은 다음과 같다.\n",
    "'''\n",
    "1. 대부분의 수치 계산 라이브러리가 큰 배열을 효율적으로 처리할 수 있도록 고도로 최적화되어있다.\n",
    "2. 커다란 신경망에서는 데이터 전송이 병목으로 작용하는 경우가 있는데, 배치처리를 함으로써 버스에 주는 부하를 줄일 수있다.(정확히는 I/O 계산에 들일 시간을 줄이고 CPU 또는 GPU 연산을 하는 시간이 많아진다.)\n",
    "컴퓨터에서는 큰 배열을 한꺼번에 계산하는 것이 분할된 작은 배열을 여러번 계산하는 것보다 빠르다.\n",
    "\n",
    "이러한 이유로 배치를 이용했을 때 이미지 1장당 처리 시간을 대폭 줄일 수 있다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 짚고 넘어갈 점 1 - argmax의 axis 옵션\n",
    "# axis=n : n번째 차원을 구성하는 원소에서(n번째 차원을 축으로) 최댓값의 인덱스를 찾도록 한다. 여기서는 1차원을 구성하는 원소들중에서 최댓값을 뽑아낸다.\n",
    "\n",
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
    "y = np.argmax(x, axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 짚고 넘어갈 점 2 - ==연산자의 사용\n",
    "# numpy 배열끼리 ==를 사용할 시 bool값을 반환한다. 이를 sum에 넣으면 false일 때 count하지 않고(0을 더하고), true일 때 count(1을 더하는)할 수 있다.\n",
    "y = np.array([1,2,1,0])\n",
    "t = np.array([1,2,0,0])\n",
    "print(y==t)\n",
    "print(np.sum(y==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seongik/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# 배치 처리\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0,len(x),batch_size): # 배치 크기만큼 건너뛰며 반복한다\n",
    "    x_batch = x[i:i+batch_size] # 배치 크기만큼의 한 다발을 x_batch로 정한다.\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p= np.argmax(y_batch, axis=1)  \n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size]) # 배치단위로 분류한 결과를 실제 답과 비교하여 정확도를 측정한다.\n",
    "    \n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 장에서 배운 내용\n",
    "# 신경망에서는 활성화 함수로 시그모이드 함수와 ReLU 함수 같은 매끄럽게 변화하는 함수를 이용한다.\n",
    "# numpy의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.\n",
    "# 기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.\n",
    "# 출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.\n",
    "# 분류에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정한다.\n",
    "# 입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
