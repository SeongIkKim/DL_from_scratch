{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅은 주로 다음의 두 경우에 일어난다.\n",
    "'''\n",
    "1. 매개변수가 많고 표현력이 높은 모델\n",
    "2. 훈련데이터가 적음\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU5bnA8d+TSUISEhJICJCEJSwiCMgScUGtW0VsVVxq1S7WqthWe/XeisJta633tqWltl5urUtb3Fu1ikgVBRfUq4gQ9jUQEMgGhJCE7MvMe/84E5gkM5NJyJnJZJ7v55NPZs6cd+bJSXKec95VjDEopZSKXFGhDkAppVRoaSJQSqkIp4lAKaUinCYCpZSKcJoIlFIqwmkiUEqpCGdbIhCRxSJyRES2+XhdRGSRiOSLyBYRmWpXLEoppXyz847gWeAKP6/PAsa4v+YAT9gYi1JKKR9sSwTGmE+AY352uQZ43ljWACkiMsSueJRSSnkXHcLPzgQKPJ4XureVtN1RROZg3TXQt2/faaeffnpQAlQqGCpqmzh0vJ4mp4sYRxSD+8WRkhBja9ldh6pocrrabY8SYXR6IjUNzVQ3NJ/YXtfopNG9vwCBzEfgiBKMAZfOXmCbiZnJAe+7fv36o8aYgd5eC2UiEC/bvP7FGGOeBp4GyMnJMbm5uXbGpVSnLN1YxMIVeRRX1JGREs/cmWOZPSXT5/7VDc3UNToZmNSHpRuLmL9kK2lNzhOvx8Q4+Nl1E5k9JZOCY7UcrW4gOT6GkQMTef7z/Tz2/h6aml1k9I/neGkNaR4ndKdAVZQQG+3wG3Oax0m+rSr399P6xxMXY73PgL6xfOvsYewoOc5TH+/zWk6A1fMvAaDgWB3Prv6SWEcU35uRzaB+fU7sd+3jn3HoeEO78oP79eGNu2f4jTvSyvorn5kSz2fzLumwfAsROeDrtVAmgkJgqMfzLKA4RLGoCBfIyXzF9kPsKqk68XzS0GQqahr5zze2Uec+kRdV1DFvyRY+yjtCdloiAHExUdx01jDiYx0s+mAPz63eT01jM1dOHMLHu0tPlG1R1+Tk529u460tJby/8/CJ7RMy+7Gt6DjnjkxldHoiL31xAFebSydjIDo6im/kDMWfV3IPUtPgbLd9cL84bpsxgomZyZw7KhWR1tdr10zO5K3NJRRV1LUrm5ESz5DkeACGJMczPXuA18+eN2sc85dsbfVzx8c4mDdr3InyvkRaWX/l584c22HZQIUyESwD7hGRl4GzgUpjTLtqIaXs9sb6Qv5zaeuT+QOvbcHlMmwsqCApLproKGHRh/ntyjqiBGebs3F9k4ulm1pf07yxsYjByXF8lFfK1yYOYUhyHC+vK2hV/eKpqr6Z3APHuPfSMUwelsKukiqeXf0lN0zLYsF1E4l2RPHiGu8XeLUNTh66arzfn3lSVrKPk9Ppfu9mAObOHHtKJ6aW9+/MXVSklu2O8oEQu2YfFZF/ABcBacBh4BdADIAx5kmxLjX+hNWzqBa4zRjTYZ2PVg2pU5G7/xhHqxsZkhzH+Ix+PPjaFt7YWOS1TrJvH0erq+Zrp2Ty2+snER0lNLlcvLW5hJ/8c7PPz9r36ysB+GzvUeY8v576Zie/mj2RW84eBoAxhhm//ZDiivp2ZTNS4vjswUvaXZF7mrHgQ69X5oFWGXS2Squ7yqrQEJH1xpgcr6+F2zTUmghUZ1Q3NPP0J/s4b1Qqn+45yp9WnbyqT0/qw5Gq9nWvnq44YzAPXDGWzYUVXHNmJlFRrU/MgZ6Md5Ycp7y2kfNGpbXar6WNoO3V9W/cbQT+nEpZFXn8JYJQVg0p1S1+885O+kQ7GJnW98RVarRDuGRsOoerGthUUMGiD/YA8M2codx63gjW7T/GP9Ye5J5LRvPUx/u8nsxjHVH8+rqJDOgby8iBiV4/O9BqknFD+nktH8oqB6Va6B2BCmvbiyv52qJPiY6CaEcU9U2tu0Q6BB67aQoVdU3UNzq544LsdtUtp3plrdUkKhzoHYEKW81OF29tKeHdbYdodjfKJsQ6uDFnKDNGp/Loyt3EOIQmp6HZ1b5ffGpiH646M8PvZ3RHY56e+FU400Sgeiyny3DjU5+z4WAFmSnxJMdbA6UOH69n2eZiYh1RNDpdzJ05loUr8ry+R2kHbQAt9GSuIpkmAtWjeFazpCTEUF7bxMNXjee754440VDb0OzkzY3F7DtaQ0Ksg9vPz+aJj/Z67YqZkdJxP22lIp0mAtVjtK2rL69tQgSS42Ja9dbpE+3gxrNaD5j68SWj+c07u1pt6+5BN0r1VroegeoxFry7q90oW2Pg9+/t7rDsXV8ZxWPfnExmSjyC1X1Tu1EqFRi9I1AhtevQcZ5bvZ+q+mYOVbYfWAVQ7KVrpzdaz69U12giUCFTVd/EHc/lUlbdyIC+sSTEOqhtbD//jdbzK2UvTQSq2wXSr76+ycnPlm6juKKOf/7gPKYN7++zP7/W8ytlL00Eqlu1PZkXVdQxf8kWwLqyf2HNASrrmthRfJyj1Q3cd9kYpg3vD+hIWaVCRUcWq05xuQz7jtYwOv3klAulVQ00NDvJ6p/gc+6d+BgHdU1O+ifEMDy1L+lJffj++dmcnT3A78RqSqnuoSOLVbdodrp44PUtLNlQxK+uncC3zh5O3qEqvvXXLzhW08CVE4f4bNita3Ly40tG86OLRhMf63/RFKVUcGkiUAF7aNl2lmwoIjMlnv9+aycVtU385f/20Sc6ittmZPPs6v0ktJm6uUVyfAw/uVzr+pXqiXQcgQpIbWMzr60v5KazhvL6D88jNjqKhSvyGD0wkX/edR4///p4bpiaRa2XJBAf4+CXV58RgqiVUoHQOwLl1yvrDpLeL46mZheNzS6uOjODwclxvHLXOdQ0NDNt+MnlCP/tsjG8sbGIRqeLwf3iOHy8Xht8lQoDmgjUCS99cYCX1hzk0RvPZNyQflTWNfHzN7eT1Ceac0elktQnmrNGWCf+0we3n18/MyWe+2eeRkllPb+4Su8AlAoXmggUAE9+vJcF7+zCESVc9+fPSIyLOTFzZ1lzI29tKeFrk4YQG+2/NnHOhaOCEa5SqhtpG0EEc7kMDc1O/rAyjwXv7OKqMzN48Iqx1De5Wk3f3DLf22Xj0kMUqVLKTnpHEKHKqhu44cnP+fJoDWAt4fjr6yZy4e9WtVvI3WWsBt/Lxg0KfqBKKdtpIohAxhjmL9lKUXkd9102hqz+CVw3xVqY3dc4gPomJ0lxMUGOVCkVDJoIItCruQWs3HGYn145jjsvHNnqtYyUeK8jg3XiN6V6L20jiACr84+eOLkfKKvhl//awbkjU7n9/Ox2+86dOZb4mNYjf3XiN6V6N70j6OXyj1Rxy1+/IDpKuGBMGvvLanFECY/eeGarVb9a6MRvSkUeTQS93JubiokSuPGsoazfX05cjIM/3jjZb1WPLvCiVGTRRNBLWWsC7KKoop4+0VFMHzGAX187MdRhKaV6IE0EvURVfRP3vryJitpGMLC95DgNzS4AGppdzF+yFUCv9JVS7WhjcS/xztZDfLjrCDGOKDYWVJxIAi3qmpwsXJEXouiUUj2ZJoJeYtnmYoanJvDynHN87hPoIvBKqciiiaAXOFJVz+q9R7n6zAxExGdDsI4FUEp5o4mgF3hrcwkuA9dMzgB0LIBSqnO0sTjMfb63jN+vzGPy0BRGpycBOhZAKdU5mgjC2MGyWr73zFqGDUjgqe9Ma/WajgVQSgVKq4bC2JKNhTQ6XTz7/ekM6hcX6nCUUmFKE0EYamx2YYxh2eZizs4eQKY2AiulToGtiUBErhCRPBHJF5F5Xl4fJiKrRGSjiGwRkSvtjCfc7Sut5q4Xchn/0Lv8/M1t7Cut4ZrJWv2jlDo1tiUCEXEAjwOzgPHAzSIyvs1uPwNeNcZMAW4C/mxXPL3B3Ne28Fl+GRMyk3lxzUFiHMKsCYNDHZZSKszZ2Vg8Hcg3xuwDEJGXgWuAHR77GKBlFfRkoNjGeMKay2XYUXycm6cPY/6Vp/Ort3eSEOsgJSE21KEppcKcnYkgEyjweF4InN1mn4eBlSLyY6AvcJm3NxKROcAcgGHDhnV7oOHg4LFa6pqcjB2cSIwjioevPiPUISmlegk72wjaT3ZPu+VwbwaeNcZkAVcCL4hIu5iMMU8bY3KMMTkDBw60IdSeb9ehKgDGDu7XwZ5KKdU5diaCQmCox/Ms2lf93A68CmCM+RyIA9JsjCls7T5chQicNigx1KEopXoZOxPBOmCMiGSLSCxWY/CyNvscBC4FEJFxWImg1MaYwlbeoSqGDUggIVbHACqlupdtZxVjTLOI3AOsABzAYmPMdhF5BMg1xiwDfgL8RUT+Hava6HvGmLbVRxFryfoCHn1vD8UVdTiihNMHJ4U6JKVUL2Tr5aUxZjmwvM22hzwe7wBm2BlDuPr9il38adXeE8+bXYZdh6pYurFIp45QSnUrrWfooZ5dvb/dtmaXYeGKPE0ESoWThWOg5kj77X3TYe4e+8sHQBNBD1Xd4PS6XReXURHtVE6KoSrrrZy/7d1dPgCaCHqgukbvSQB0cRnVC4TqpOqv7LEvwdVsfQGkjgZHDDQ3Ql25/7IlW8DVZO17NA9iE63y0X0gqoNTbGMtHNkBR/dYnwMQEwdHdoKzETKn+S/fTTQR9ECbCysAiHVE0eg8ufawLi6juo3dV8fGwOFtEBUD6adbz/d/Cnnv+D+pHvgcWoYSRUVDTLx1cj26B+oq/Mf1t5nW/nXlUHMU4vqBywnNdZA6xn/ZRZNbP+/TD5IGQ1k+GJf3Mi2eusD/6/78dgQ4G9pvj+kLjmhY/2zX37sTNBH0QLn7jwHw8NXjeXzVXl1cRnUflwt2v+v/ZLzrbSjNg6ZayMyxrpKb6yErB4rW+y/7zjw4ttc6gR7bZ21PHgaN1VB3DMThvWyLZ67w/VpMX/9lo2OhoQoSUiF9nPU4ygGOWCjd5b/s7Ces/aIc4GyyklbNURh3NfQbAm//xHfZbzwL0fFW2bQx0FAN5futuwSXE16/3XfZs+6AETNg4OmQMMBKmI3V0C8TECj/Ev53qv/Yu4GEW2/NnJwck5ubG+owbPW9Z9ZSXFHHyn//SqhDUR2xuyGwudG6Mo6KgpLNUHXYumKuKoH3HrJOrm3FD4CL/xNKNlllKgth2vesq+LP/se6wg6ERHV8NdxWdBwMHAuJg2HsLCuJfPmJdZLLOgvOuA5+PcR3+W8vOfnY2WSdFAdkQ/oZVpXJw8m+yz5c6T+2cCzbHeXdRGS9MSbH22t6R9ADbS2s5NJx6aEOQwWiK3XWzY2w+x3Y8qr/8q99H3b+C1KGwYBRsGdFYDHVHYPl90NCGgyZBCnD4dM/Wq8NmgDX/83/VeodH1hXtlExVjKJjrOSQuE6SB0FL1zru+wD+yC2zZX79DsDixtg9KWB7xsu+qb7TvbBKB8ATQQ9THlNI2U1jYxJ18FjnWJHnTdRcM4PYeRXYMBI6+RYmgfb34Bz77Ea9Px57irrZFqYa9UD9+kH/UfA4e3QVOO+/fcj/32YfAsc2gYHP4eLfwYjLwLjtK76Hz/Ld9n7tkLyUBD3lF/FG6H+OGRfaG3zlwiyPC4ah5938nHG5Pb7ttU2CXS3UzkphqrsqXbx7KYuov5oIuhh8kurARitcwp1TleuzJ1NVs8Qn/u4YO1TsOZx6+mIC6w68qZa6yRdlu8/ptpyq2pkwnVWw2VNmVXnO/lmOO0KGHUJPDLAd/kHD5w8kXdWSptZejOmdO197BCqk2qoyoYBTQQ9zJ7D7kQwMAITQVev6p1N/t9344twvNiq705MtxosC9bC1lchx8+VMcD9e6xGzy8/gdX/CxlTYcK1sPwBiO/vv+wPP/X/eke6mgQCEaqrY+j1J9VwpImgh8k/Uk18jCMy1yHu7FW9MbDtdfjgEf/v++bd7bfFJMDQs+GLJ/yXTRjgbujMgRn3WnXlIjBkCiT0h0U96Eq7M/TqWHnQRBBiO0uO88f3dnP9tCy+Om4Q+aXVjErvS1SUjVeD4ejwduuEfmQnxKXA9X+FA5/BR7+BQRP9l73jAxg8yTqB15RaCSQ+xUoGH/4X/N+jgcUQ5dH1Mcs90CeUDYFBaERUkUETQYi9sbGIlTsOs3LHYb577nDyD1cxPdtPvXFv0FQH1Ueg/3DreX0lbPqH/zJPX2QlgOl3wu4V8OL1VgPsmTfDNX+GR/xU03g2fvbLaP3apQ8Fngi8CWVDoF6Zq26iiSDENhdUMCkrmfFD+vHSFwdxugxjBvWiHkPGwIbnYOdb1hX5uffAip9aw+ovfQgaa+CLp6Chg/7QU78LF82Hvmlw3r/BC9dZj69aZPWx1ytrpbpME0EIOV2GrUWV3JgzlLsvHs2yzcXUNjoZ1Zsaincug3/da829UnsMnr/aGiE64nx4/xfWPuOuggvnwlMX+n6fr3lctSemw12fWImlpUFVr6yV6jJNBCGUf6Sa2kYnk7KSGZjUh+/PyOZPq/LDewGaX2dao0Hbqj8O96yDzx+H8ddYdfY7llpTAaSPs/bpzJV5lJ2L6ykVWTQRhFDL5HJnDk0B4N7LxnDx6emMSLN5UE53aKqzZk5MGHDyqnzLP70nAbBO8H3T4LJfnNw24brW++iVuVIhoYkghDYXVJAUF012qnXij3FEMW14B33TQ6mxxpqYSxzw7NehKNca4Xr9X6weON66aSqlejxNBCG0udBqKA6LrqIuFyyeaTX+nnWHlQRyvg8Hv4CXv22N0E0ZBmV6Va9UuNFEECK1jc3sKqnirq+MDHUorfka3RuXbHXzBHjrPqvv/pWPQu1ReGaWVVX0nTfgsQnBjVcpdco0EYTIpoIKml2GnBE9bMyAr1G89ZXWJGbn/Mia/njmf1sNtonp8INPrTl1+oRxI7dSEUwTQYjk7i9HBKYO68FtAm2d80M490cw7dbWs0zGeEyHoX3ylQo7mgiCyOky3Lp4LbOnZLJu/zHGDkoiOT4mdAEZY01vfHg7TLwBtr7mf/9p37O++5tqWHv+KBV2NBHYbOnGIhauyKO4oo7UxFiOVjeyo+Q4jc0uZk/J6PgN7FJ7DF79Luz/P+v5iv+0Fsv2x+655pVSIaGJwEZLNxYxf8lW6pqcAByttk60x2qs72eFqn2g6hC8dAOU7oZZv7PWpf3iSWtOnnceCE1MSqmQ0URgo4Ur8k4kAU9xMVHUN7nsGzPgb17/yTdbc/sA3Px3GH2Z9TjrL9b3T36vdfxKRRhNBDYqrqjzur2hycWim6eQ1T/Bng/2N6//Z/8Dk74JX3nQWn+2La3jVyri6IQtNsrwsbhMRko8V59pU/vAkV3+X5/0Tbj2Ke9JQCkVkTQR2OjuS9qfbONjHMydOdaeD3Q2w2u3+d/n64/ZuwSiUirsaNWQDWoamnl05W62FVsjcQcm9uFodQMZKfHMnTmW2VMy7fngdX+15vn3J9am6iilVNjSRNDNKuuauO2ZtWwurGREagJXThzM47dMRey8Cm+ohk0vwapfwahLYO+H9n2WUqrX0UTQjcqqG/jO39ay50gVj98ylSsmDA7OB7/6Hevkn3UWfP2P8Nevas8fpVTANBF0k4ZmJzf/ZQ0Hymr5y3dzuGhskE66e1dZSeCyX8L591nbtOePUqoTNBF0kx3Fx9l9uJrff+PM4CUBY+CDR6BfFpz9g+B8plKq17G115CIXCEieSKSLyLzfOxzo4jsEJHtIvJ3O+Ox0+7DVQDk2L2wjLMJSrZYSWDnv6B4A1w0D2Li7P1cpVSvZdsdgYg4gMeBrwKFwDoRWWaM2eGxzxhgPjDDGFMuImFbib3rUBXxMQ6GDbCxV86WV2Hlz6D6MFz4AOx4E9JOgzNvtu8zlVK9np1VQ9OBfGPMPgAReRm4BvDs33gn8LgxphzAGONjSGzPl3eoitMGJdq32pizGd55EPplQuY0+OR31vYbnweH1vAppbrOzqqhTKDA43mhe5un04DTROQzEVkjIld4eyMRmSMiuSKSW1paalO4pybvUBVjB9u4MMuBT6HuGHzlAbjhGRhxgfU17mr7PlMpFRHsvJT0dmlsvHz+GOAiIAv4PxGZYIypaFXImKeBpwFycnLavkfIlVY1UFbTyNjB/ez7kB3LrAXiR19mtQfc+i8wLh0lrJQ6ZQElAhF5HVgMvGOMcQX43oXAUI/nWUCxl33WGGOagC9FJA8rMawL8DN6hLxDVkPx2EHdeEfgawbR/znT6h4qAuLovs9TSkWsQKuGngBuAfaIyAIROT2AMuuAMSKSLSKxwE3Asjb7LAUuBhCRNKyqon0BxtRj5Ll7DHVr1ZC/GUSVUqobBZQIjDHvG2O+BUwF9gPvichqEblNRLyutWiMaQbuAVYAO4FXjTHbReQREWmp2F4BlInIDmAVMNcYU3ZqP1LwbS6oILVvLAOT+oQ6FKWU6rSA2whEJBX4NvAdYCPwEnA+cCtWHX87xpjlwPI22x7yeGyA/3B/haXymkbe3X6Ib0zLCnUoSinVJYG2ESwBTgdeAK4yxpS4X3pFRHLtCi4cvJJbQGOzi++eO6L73rTqUPe9l1JKdSDQO4I/GWO8TmlpjMnpxnjCitNleHHNAc7OHtC97QOr/7f73ksppToQaGPxOBFJaXkiIv1F5Ec2xRQ29hyporC8jm/kDO1450CV7YW1f4FoH1NG6AyiSqluFugdwZ3GmMdbnring7gT+LM9YYWHljWJRw7s2z1vaAwsnwuOWLhnHfQb0j3vq5RSfgR6RxAlHiuruOcRirUnpPBRUlkPwJDkbprwbfUi2PsBXPpzTQJKqaAJ9I5gBfCqiDyJNTr4B8C7tkUVJg5V1hMl1lKUXVZ+AD7/E1QWQd7bMP4aOOuO7gtSKaU6EGgieBC4C/gh1tQRK4G/2hVUuCiprGdQvziiHacwZdMHj8COpdB3IJz3Y2uBmSgdMayUCp6AEoF7Wokn3F/KraSyjsGnUi107EvYvsRKAF99pPsCU0qpTgh0HMEY4DfAeODEmc8YM9KmuMJCSWU9p59Kt9HViyAqGs6J+A5YSqkQCrRO4xmsu4FmrLmBnscaXBaxjDEcqqxncL/4rr1BwTrY8DxM/hYkBWmRe6WU8iLQRBBvjPkAEGPMAWPMw8Al9oXV8x2vb6a20UlGSheqhmqOwmu3Qb8MuOwX3R+cUkp1QqCNxfUiEoU1++g9QBEQ0SObSiqtMQSdbiPIXWw1EDfWwPffhXib1zhWSqkOBHpHcB+QAPwbMA1r8rlb7QoqHHRpDMHmV+Ctf4fBE+HOVdaSk0opFWId3hG4B4/daIyZC1QDt9keVRg4dCIR+Gkj8LW4zJFdMHiCTZEppVTndHhHYIxxAtM8RxYrKKmoswaT+VuDQBeXUUqFgUDbCDYCb4rIP4Galo3GmCW2RBUGSirrGZjUh5hTGUymlFI9QKCJYABQRuueQgaI2ERQVFFHRkoXu44qpVQPEujIYm0XaKOgvJapw7THj1Iq/AU6svgZrDuAVowx3+/2iMJAk9NFcUU9sycnhDoUpZQ6ZYFWDb3l8TgOuBYo7v5wwkNJRT1Ol2Fofz+JoP441vx87fKnLi6jlOpRAq0aet3zuYj8A3jflojCQEF5LQBDB/hJBOufBQzc+aGOF1BK9Whd7fIyBhjWnYGEk4PHWhKBj8bipjr4/HHI/oomAaVUjxdoG0EVres4DmGtURCRCo7VEh0lvgeTffoYVB+CGxYHNzCllOqCQKuGTmGu5d7n4LFaMvvH44jyMsbu2Jfw6R9hwg0wYkbwg1NKqU4KqGpIRK4VkWSP5ykiMtu+sHq2gvI6hvlqH/hogbXGwOX/FdyglFKqiwJtI/iFMaay5YkxpgKI2PmTC47Vem8orjoE216Hqd+1pphWSqkwEGgi8LZfoF1Pe5XqhmaO1TR67zqauxhczTD9zuAHppRSXRRoIsgVkT+IyCgRGSkifwTW2xlYT3WwzEePoeZGKxGcNhNSR4UgMqWU6ppAE8GPgUbgFeBVoA64266gerL9Zdace9lpfVu/ULIZakph8i0hiEoppbou0F5DNcA8m2MJC/tKqwEviaB4g/U9MyfIESml1KkJtNfQeyKS4vG8v4issC+snmvf0RqGJMeRENsmhxZtgMRB2kislAo7gVYNpbl7CgFgjCknQtcs3lda0/5uAKw7goypoOv3KKXCTKCJwCUiJ6aUEJEReJ1NrXczxrCvtJqRA9skgvpKOLpHp5NQSoWlQLuA/hT4VEQ+dj+/EJhjT0g9V3ltE8frm8lOS2z9QvEmwEDmlJDEpZRSpyLQxuJ3RSQH6+S/CXgTq+dQRGlpKB7pq6E4Y2qQI1JKqVMXaGPxHcAHwE/cXy8ADwdQ7goRyRORfBHx2etIRG4QEeNONj3WvqNW19FWVUMuF+x4E1LHQMKAEEWmlFJdF2gbwb3AWcABY8zFwBSg1F8BEXEAjwOzgPHAzSIy3st+ScC/AV90Iu6Q2FdaQ4xDyPRcq3jHG1C8ES74j9AFppRSpyDQRFBvjKkHEJE+xphdwNgOykwH8o0x+4wxjcDLwDVe9vsv4HdAfYCxhMze0mqGDUgg2uE+bM4m+OARSD8DJn0ztMEppVQXBZoICt3jCJYC74nIm3S8VGUmUOD5Hu5tJ4jIFGCoMcZzKcx2RGSOiOSKSG5pqd8bEdu4XIbc/cc4Myvl5MaSzVC+37obiHKEJC6llDpVgTYWX+t++LCIrAKSgXc7KOatQ/2JLqciEgX8EfheAJ//NPA0QE5OTki6re48dJzy2iZmjE47ufHIDut7pjYSK6XCV6dnEDXGfNzxXoB1BzDU43kWre8ikoAJwEdiDcIaDCwTkauNMbmdjctuq/PLANokgl0QHQ8pI0ITlFJKdYOurlkciHXAGBHJFpFY4CZgWcuLxphKY0yaMWaEMWYEsAbokUlg6cYifr8yD4Drn1jN0o1F1gulO2HgaRBl52FUSil72bamgDGmWUTuAVYADmCxMWa7iDwC5Bpjlvl/h55h6cYi5i3ZQkOzC4CiijrmL9kKwOwjuyD7wlCGp5RSp8zWxWWMMcuB5W22PeRj34vsjNv8j2EAABL8SURBVKWrFq7Io77J1WpbXZOTJ97dwOyGYkg/PUSRKaVU99A6jQ4UV3gfQJ14PN96MHBcEKNRSqnup4mgAxkp8V63n9X3sPVA7wiUUmFOE0EH5s4cS1SbjrDxMQ6+MawaYhIgeZj3gkopFSY0EXRg9pRM+sXFEB/jQIDMlHh+c91ERrn2Q/o47TGklAp7tjYW9wY1Dc1U1DVx/+Wncc8lY6yNLhe8uxkm3Rja4JRSqhvo5WwH9rqnnh6d7rEGwbG90HAcMnT9AaVU+NNE0IH8I14SQfFG67smAqVUL6CJoAP5R6qJjhKGp3qsQVC80WooTutoAlallOr5NBF0YM+Rakak9SXG4XGoijfC4Eng0CYWpVT400TQgV2HjjN2UNLJDc5ma/pprRZSSvUSmgj8qKxrouBYHeMz+p3ceHQ3NNVqIlBK9RqaCPzYWXIcgDM8E4E2FCulehlNBH5sL7YSwfi2iSA2CVJHhygqpZTqXpoI/NheXMnApD6kJ8Wd3Fi8ATIm64hipVSvoWczP3YUH29dLdTcCIe2WYlAKaV6CU0EPtQ3OdlzpLp1IijdCc4GbR9QSvUqmgh82HO4GqfLcEZG8smN2lCslOqFNBH4kF9aBcBpgzymlihaD3Ep0D87RFEppVT306GxPuw/WosIjHpuKtQcaf3iL1OgbzrM3ROa4JRSqhvpHYEPB8pqyEiOR9omgRa+tiulVJjRRODD/rJaRqQlhDoMpZSynSYCHw4eq2XYgL4d76iUUmFOE4EXlXVNHKtpZESq3hEopXo/TQReHCyrBWi9BoFSSvVSmgi82F9WA2C1EcQle9+pb3oQI1JKKfto91EvDrgTwbABCTDxRtj0Ejx4AKJjQxyZUkp1P70j8OJAWS3pSX1IiI2GA5/BsHM0CSilei1NBF4cKKtleGoC1FXAkZ0w7NxQh6SUUrbRROBFQbm762hhLmBg6NmhDkkppWyjiaCNxmYXh47Xk9k/Hgq+AImCzGmhDksppWyjiaCNQ5X1GANZLYlg0ATok9hxQaWUClOaCNooLLfGEGQlx1izjWq1kFKql9NE0EZheR0A2c4D0Fht9RhSSqleTBNBG4UVdUQJDKzYZG0YOj20ASmllM1sTQQicoWI5IlIvojM8/L6f4jIDhHZIiIfiMhwO+MJRGF5LYP7xRFdtA6ShkDy0FCHpJRStrItEYiIA3gcmAWMB24WkfFtdtsI5BhjJgGvAb+zK55AFZbXnewxNHQ6iIQ6JKWUspWddwTTgXxjzD5jTCPwMnCN5w7GmFXGmFr30zVAlo3xBKSovI7xibVQcRCGavuAUqr3szMRZAIFHs8L3dt8uR14x9sLIjJHRHJFJLe0tLQbQ2yt2WmNIZgWtdvaoD2GlFIRwM5E4K1OxXjdUeTbQA6w0NvrxpinjTE5xpicgQMHdmOIrZVU1uN0GU5r3AHRcTB4om2fpZRSPYWds48WAp4trVlAcdudROQy4KfAV4wxDTbG06GiCqvraEb1NsiYohPNKaUigp13BOuAMSKSLSKxwE3AMs8dRGQK8BRwtTEm5KvB7z5cBRgSK3fD4EmhDkcppYLCtkRgjGkG7gFWADuBV40x20XkERG52r3bQiAR+KeIbBKRZT7eLihy95dzZtJxoppqIP30UIailFJBY+vCNMaY5cDyNtse8nh8mZ2f31m5+4/xrfRKKAIGaiJQSkUGXaHMraiijuLKeqYPO2xt0ESgVK/S1NREYWEh9fX1oQ7FVnFxcWRlZRETExNwGU0Ebrn7jwEwWgohcRAkDAhxREqp7lRYWEhSUhIjRoxAeulAUWMMZWVlFBYWkp2dHXA5nWvILXd/OX1jHaRU74WBY0MdjlKqm9XX15OamtprkwCAiJCamtrpux5NBIDLZfg0/yhTh6UgpXkwcFyoQ1JK2aA3J4EWXfkZNREA/9pSzJdHa/jO+CjQHkNKqQgT8YmgyeniD+/tZtyQflzW3z2UQRuKlYp4SzcWMWPBh2TPe5sZCz5k6caiU3q/iooK/vznP3e63JVXXklFRcUpfXZHIjoRrN57lBue/JwDZbXcf/lpRG14HhLSIGNqqENTSoXQ0o1FzF+ylaKKOgxWr8L5S7aeUjLwlQicTqffcsuXLyclJaXLnxuIiO01dPh4Pbc9s460xD789vqJXJJWCXtWwEXzISYu1OEppWz0y39tZ0fxcZ+vbzxYQaPT1WpbXZOTB17bwj/WHvRaZnxGP35x1Rk+33PevHns3buXyZMnExMTQ2JiIkOGDGHTpk3s2LGD2bNnU1BQQH19Pffeey9z5swBYMSIEeTm5lJdXc2sWbM4//zzWb16NZmZmbz55pvEx8d34Qi0FrF3BIs+2IPLGF6ecw7fPGsYsubP4OgDObeHOjSlVIi1TQIdbQ/EggULGDVqFJs2bWLhwoWsXbuWX/3qV+zYsQOAxYsXs379enJzc1m0aBFlZWXt3mPPnj3cfffdbN++nZSUFF5//fUux+MpIu4Ilm4sYuGKPIor6shIiefW84bzyroCbp4+jKEDEmDXclj/LOTcBon2zW6qlOoZ/F25A8xY8OGJSSg9ZabE88pd53ZLDNOnT2/V13/RokW88cYbABQUFLBnzx5SU1NblcnOzmby5MkATJs2jf3793dLLL3+jsBbXd9vlu/CEQU/vmQ0lGyB1++wZhu9/FehDlcp1QPMnTmW+BhHq23xMQ7mzuy+MUZ9+/Y98fijjz7i/fff5/PPP2fz5s1MmTLF61iAPn36nHjscDhobm7ullh6/R3BwhV51DW1bowxQL/4WNIph79/E+JT4OZ/QGxCaIJUSvUos6dYa2h51iTMnTn2xPauSEpKoqqqyutrlZWV9O/fn4SEBHbt2sWaNWu6/Dld0esTQbGX2zuAmqpK+MdNUF8Jt6+ApMFBjkwp1ZPNnpJ5Sif+tlJTU5kxYwYTJkwgPj6eQYMGnXjtiiuu4Mknn2TSpEmMHTuWc84J7jK5YozXRcN6rJycHJObmxvw/mUPDyeV9n1wG4khlmbrTmDsrO4MUSnVA+3cuZNx4yJj1gBvP6uIrDfG5Hjbv9ffEXhLAgCxNMHMX2sSUEpFvF7fWOzXOT8KdQRKKRVykZ0IImACKqWU6khkJwKllFKaCJRSKtL1/kTQN71z25VSKsL0+l5DzN0T6giUUuFm4RioOdJ+e9/0Lp9TKioq+Pvf/86PftT5TiqPPfYYc+bMISHBnkGvvf+OQCmlOstbEvC3PQBdXY8ArERQW1vb5c/uSO+/I1BKqbbemQeHtnat7DNf87598ESYtcBnMc9pqL/61a+Snp7Oq6++SkNDA9deey2//OUvqamp4cYbb6SwsBCn08nPf/5zDh8+THFxMRdffDFpaWmsWrWqa3H7oYlAKaWCYMGCBWzbto1NmzaxcuVKXnvtNdauXYsxhquvvppPPvmE0tJSMjIyePvttwFrDqLk5GT+8Ic/sGrVKtLS0myJTROBUiry+LlyB+DhZN+v3fb2KX/8ypUrWblyJVOmTAGgurqaPXv2cMEFF3D//ffz4IMP8vWvf50LLrjglD8rEJoIlFIqyIwxzJ8/n7vuuqvda+vXr2f58uXMnz+fyy+/nIceesj2eLSxWCml2rKh27nnNNQzZ85k8eLFVFdXA1BUVMSRI0coLi4mISGBb3/729x///1s2LChXVk76B2BUkq1ZUO3c89pqGfNmsUtt9zCuedaq50lJiby4osvkp+fz9y5c4mKiiImJoYnnngCgDlz5jBr1iyGDBliS2Nxr5+GWimlQKeh9jcNtVYNKaVUhNNEoJRSEU4TgVIqYoRbVXhXdOVn1ESglIoIcXFxlJWV9epkYIyhrKyMuLi4TpXTXkNKqYiQlZVFYWEhpaWloQ7FVnFxcWRlZXWqjCYCpVREiImJITs7O9Rh9Ei2Vg2JyBUikici+SIyz8vrfUTkFffrX4jICDvjUUop1Z5tiUBEHMDjwCxgPHCziIxvs9vtQLkxZjTwR+C3dsWjlFLKOzvvCKYD+caYfcaYRuBl4Jo2+1wDPOd+/BpwqYiuKK+UUsFkZxtBJlDg8bwQONvXPsaYZhGpBFKBo547icgcYI77abWI5HUxprS2791DaFydo3F1Xk+NTePqnFOJa7ivF+xMBN6u7Nv22wpkH4wxTwNPn3JAIrm+hliHksbVORpX5/XU2DSuzrErLjurhgqBoR7Ps4BiX/uISDSQDByzMSallFJt2JkI1gFjRCRbRGKBm4BlbfZZBtzqfnwD8KHpzaM9lFKqB7Ktashd538PsAJwAIuNMdtF5BEg1xizDPgb8IKI5GPdCdxkVzxup1y9ZBONq3M0rs7rqbFpXJ1jS1xhNw21Ukqp7qVzDSmlVITTRKCUUhEuYhJBR9NdBDGOoSKySkR2ish2EbnXvf1hESkSkU3urytDENt+Ednq/vxc97YBIvKeiOxxf+8f5JjGehyTTSJyXETuC8XxEpHFInJERLZ5bPN6fMSyyP33tkVEpgY5roUissv92W+ISIp7+wgRqfM4bk8GOS6fvzcRme8+XnkiMjPIcb3iEdN+Ednk3h7M4+Xr3GD/35gxptd/YTVW7wVGArHAZmB8iGIZAkx1P04CdmNNwfEwcH+Ij9N+IK3Ntt8B89yP5wG/DfHv8RDWwJigHy/gQmAqsK2j4wNcCbyDNVbmHOCLIMd1ORDtfvxbj7hGeO4XguPl9ffm/h/YDPQBst3/r45gxdXm9UeBh0JwvHydG2z/G4uUO4JAprsICmNMiTFmg/txFbATa4R1T+U5DchzwOwQxnIpsNcYcyAUH26M+YT241x8HZ9rgOeNZQ2QIiJDghWXMWalMabZ/XQN1jieoPJxvHy5BnjZGNNgjPkSyMf6vw1qXO4pbm4E/mHHZ/vj59xg+99YpCQCb9NdhPzkK9Zsq1OAL9yb7nHf4i0OdhWMmwFWish6sab1ABhkjCkB6w8VSA9BXC1uovU/aKiPF/g+Pj3pb+77WFeOLbJFZKOIfCwiF4QgHm+/t55yvC4ADhtj9nhsC/rxanNusP1vLFISQUBTWQSTiCQCrwP3GWOOA08Ao4DJQAnW7WmwzTDGTMWaMfZuEbkwBDF4JdagxKuBf7o39YTj5U+P+JsTkZ8CzcBL7k0lwDBjzBTgP4C/i0i/IIbk6/fWI44XcDOtLzaCfry8nBt87uplW5eOWaQkgkCmuwgaEYnB+kW/ZIxZAmCMOWyMcRpjXMBfsOm22B9jTLH7+xHgDXcMh1tuN93fjwQ7LrdZwAZjzGF3jCE/Xm6+jk/I/+ZE5Fbg68C3jLtS2V31UuZ+vB6rLv60YMXk5/fWE45XNHAd8ErLtmAfL2/nBoLwNxYpiSCQ6S6Cwl0H+TdgpzHmDx7bPev2rgW2tS1rc1x9RSSp5TFWY+M2Wk8DcivwZjDj8tDqSi3Ux8uDr+OzDPiuu2fHOUBly+19MIjIFcCDwNXGmFqP7QPFWisEERkJjAH2BTEuX7+3ZcBNYi1Wle2Oa22w4nK7DNhljCls2RDM4+Xr3EAw/saC0RreE76wWth3Y2X0n4YwjvOxbt+2AJvcX1cCLwBb3duXAUOCHNdIrF4bm4HtLccIa1rwD4A97u8DQnDMEoAyINljW9CPF1YiKgGasK7Gbvd1fLBu2x93/71tBXKCHFc+Vv1xy9/Yk+59r3f/fjcDG4CrghyXz98b8FP38coDZgUzLvf2Z4EftNk3mMfL17nB9r8xnWJCKaUiXKRUDSmllPJBE4FSSkU4TQRKKRXhNBEopVSE00SglFIRThOBUjYTkYtE5K1Qx6GUL5oIlFIqwmkiUMpNRL4tImvd884/JSIOEakWkUdFZIOIfCAiA937ThaRNXJyvv+WOeJHi8j7IrLZXWaU++0TReQ1sdYIeMk9ihQRWSAiO9zv8/sQ/egqwmkiUAoQkXHAN7Em3psMOIFvAX2x5jiaCnwM/MJd5HngQWPMJKxRnS3bXwIeN8acCZyHNYIVrJkk78OaX34kMENEBmBNs3CG+33+296fUinvNBEoZbkUmAasE2t1qkuxTtguTk5C9iJwvogkAynGmI/d258DLnTP1ZRpjHkDwBhTb07O87PWGFNorMnWNmEteHIcqAf+KiLXASfmBFIqmDQRKGUR4DljzGT311hjzMNe9vM3J4u3aYFbNHg8dmKtHtaMNfvm61iLjbzbyZiV6haaCJSyfADcICLpcGKd2OFY/yM3uPe5BfjUGFMJlHssUvId4GNjzR1fKCKz3e/RR0QSfH2ge975ZGPMcqxqo8l2/GBKdSQ61AEo1RMYY3aIyM+wVmiLwpqZ8m6gBjhDRNYDlVjtCGBNB/yk+0S/D7jNvf07wFMi8oj7Pb7h52OTgDdFJA7rbuLfu/nHUiogOvuoUn6ISLUxJjHUcShlJ60aUkqpCKd3BEopFeH0jkAppSKcJgKllIpwmgiUUirCaSJQSqkIp4lAKaUi3P8DZpZzTmtaSukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 위의 두 조건을 충족하여 일부러 오버피팅을 일으킨 예\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터를 60,000개에서 300개로 줄임(훈련데이터 적음)\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "\n",
    "#weight_decay_lambda = 0\n",
    "#weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10) # weight_decay_lambda=weight_decay_lambda\n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = [] # 에폭 단위의 정확도 저장\n",
    "test_acc_list = [] # 에폭 단위의 정확도 저장\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "#         print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 살펴보면, 훈련 데이터에는 100에폭을 지나는 시점부터 거의 100%이지만, 시험데이터는 75%가량에 머무른다.\n",
    "# 이처럼 정확도가 크게 벌어지는 것은 훈련데이터에만 적응fitting해버린 결과이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 가중치 감소weight decay 이용\n",
    "# 학습과정에서 큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과하여 오버피팅을 억제한다.\n",
    "# 오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문이다.\n",
    "# 손실함수에 가중치의 L2노름을 더하여 가중치를 감소시킨다.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터를 60,000개에서 300개로 줄임(훈련데이터 적음)\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 람다를 크게 설정할 수록 큰 가중치에 대한 페널티가 커진다.\n",
    "#weight_decay_lambda = 0\n",
    "weight_decay_lambda = 0.1 \n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10, weight_decay_lambda=weight_decay_lambda) \n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = [] # 에폭 단위의 정확도 저장\n",
    "test_acc_list = [] # 에폭 단위의 정확도 저장\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "#         print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 시험 데이터에 대한 각각의 정확도는 차이가 있지만, 가중치 감소를 이용하지 않았을 때에 비하면 차이가 줄었다(오버피팅이 억제되었다)\n",
    "# 또한, 앞서와 달리 훈련 데이터에 대한 정확도가 100%(1.0)에 도달하지 못하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 감소는 간단하게 구현할 수 있고, 오버피팅을 어느 정도 억제할 수 있으나, 신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어렵다.\n",
    "# 이럴 때에는 드롭아웃Dropout이라는 기법을 사용한다.\n",
    "\n",
    "# 드롭아웃 : 뉴런을 임의로 삭제하면서 학습하는 방법\n",
    "'''\n",
    "훈련때 은닉층의 뉴런을 무작위로 골라 삭제(dropout)한다.\n",
    "삭제된 뉴런은 더이상 신호를 전달하지 않게 된다.\n",
    "훈련 때는 데이터를 흘릴 때마다 삭제할 뉴런을 무작위로 선택하고, 시험 때는 모든 뉴런에 신호를 전달한다.\n",
    "단, 시험 때는 각 뉴런의 출력에 훈련 때 삭제 안한 비율을 곱하여 출력한다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃 구현\n",
    "# 되도록 이해하기 쉽게 구현했음.\n",
    "# 훈련 시 순전파 때 노드를 잘 삭제해두기만 하면,시험 시 순전파 때 삭제 안 한 노드의 비율을 곱하지 않아도 됨(False로 처리되어 알아서 거르고 계산해준다)\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg: # 훈련 시\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio # x와 형상이 같은 배열을 무작위로 생성 후, 그 값이 dropout_ratio보다 큰 원소만 True로 설정(삭제할 뉴런은 False)\n",
    "            return x * self.mask\n",
    "        else: # 시험 시\n",
    "            return x * (1.0 - self.dropout_ratio) # 훈련때 잘 삭제되었으면 굳이 삭제 안한 비율을 곱해주지 않아도 된다.\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask # 역전파 동작은 ReLU와 같음. 순전파 때 신호를 통과시키는 뉴런은 역전파때도 통과, 순전파 때 그렇지 않은 뉴런은 역전파 때도 통과하지 못함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2772312560217465\n",
      "=== epoch:1, train acc:0.1, test acc:0.081 ===\n",
      "train loss:2.295319788361045\n",
      "train loss:2.286789070034149\n",
      "train loss:2.292242735747316\n",
      "=== epoch:2, train acc:0.10333333333333333, test acc:0.0826 ===\n",
      "train loss:2.2875085781249926\n",
      "train loss:2.2898924692405136\n",
      "train loss:2.295072913801823\n",
      "=== epoch:3, train acc:0.11, test acc:0.0832 ===\n",
      "train loss:2.2742501402831894\n",
      "train loss:2.2984043603766673\n",
      "train loss:2.279944015739992\n",
      "=== epoch:4, train acc:0.11333333333333333, test acc:0.086 ===\n",
      "train loss:2.2965488370209686\n",
      "train loss:2.2927948509245333\n",
      "train loss:2.2708728163029592\n",
      "=== epoch:5, train acc:0.12666666666666668, test acc:0.0886 ===\n",
      "train loss:2.289646442449182\n",
      "train loss:2.2772324171272795\n",
      "train loss:2.2892550204145556\n",
      "=== epoch:6, train acc:0.13, test acc:0.0913 ===\n",
      "train loss:2.279269701504089\n",
      "train loss:2.29080813218458\n",
      "train loss:2.2849204271476258\n",
      "=== epoch:7, train acc:0.13333333333333333, test acc:0.0954 ===\n",
      "train loss:2.283123596975991\n",
      "train loss:2.277266656324837\n",
      "train loss:2.2910139693246516\n",
      "=== epoch:8, train acc:0.13, test acc:0.1004 ===\n",
      "train loss:2.281109976153458\n",
      "train loss:2.2659227866025304\n",
      "train loss:2.279773239078147\n",
      "=== epoch:9, train acc:0.13666666666666666, test acc:0.1034 ===\n",
      "train loss:2.2820387402730664\n",
      "train loss:2.2819073599397477\n",
      "train loss:2.2657011200619825\n",
      "=== epoch:10, train acc:0.13666666666666666, test acc:0.1051 ===\n",
      "train loss:2.2872662807488795\n",
      "train loss:2.2698304285974977\n",
      "train loss:2.2751324541139\n",
      "=== epoch:11, train acc:0.14666666666666667, test acc:0.1093 ===\n",
      "train loss:2.28151112975753\n",
      "train loss:2.2791015986650525\n",
      "train loss:2.2892763308413024\n",
      "=== epoch:12, train acc:0.15333333333333332, test acc:0.1113 ===\n",
      "train loss:2.2684717401664996\n",
      "train loss:2.2742619996550557\n",
      "train loss:2.2737493898725027\n",
      "=== epoch:13, train acc:0.15666666666666668, test acc:0.1152 ===\n",
      "train loss:2.2788701370620377\n",
      "train loss:2.2836414894758916\n",
      "train loss:2.270031874510347\n",
      "=== epoch:14, train acc:0.16333333333333333, test acc:0.1168 ===\n",
      "train loss:2.281565448350816\n",
      "train loss:2.2676037178867707\n",
      "train loss:2.2839601782200587\n",
      "=== epoch:15, train acc:0.17333333333333334, test acc:0.1203 ===\n",
      "train loss:2.2688310691333085\n",
      "train loss:2.26758391743064\n",
      "train loss:2.269501604093272\n",
      "=== epoch:16, train acc:0.18333333333333332, test acc:0.1272 ===\n",
      "train loss:2.254848314677418\n",
      "train loss:2.2572773280160607\n",
      "train loss:2.2650252077489186\n",
      "=== epoch:17, train acc:0.17, test acc:0.1327 ===\n",
      "train loss:2.2729163075381766\n",
      "train loss:2.2757509124897646\n",
      "train loss:2.270332061474225\n",
      "=== epoch:18, train acc:0.18, test acc:0.1377 ===\n",
      "train loss:2.255736781467261\n",
      "train loss:2.2689309544139507\n",
      "train loss:2.2670278882857335\n",
      "=== epoch:19, train acc:0.17666666666666667, test acc:0.1416 ===\n",
      "train loss:2.257208245775992\n",
      "train loss:2.2623226062566473\n",
      "train loss:2.264919481156612\n",
      "=== epoch:20, train acc:0.17666666666666667, test acc:0.1456 ===\n",
      "train loss:2.271158416665139\n",
      "train loss:2.2514791373889507\n",
      "train loss:2.2610478264664113\n",
      "=== epoch:21, train acc:0.19, test acc:0.1492 ===\n",
      "train loss:2.2769302650918393\n",
      "train loss:2.2691098255801587\n",
      "train loss:2.257343546886448\n",
      "=== epoch:22, train acc:0.20333333333333334, test acc:0.157 ===\n",
      "train loss:2.2629221156934913\n",
      "train loss:2.261728489957186\n",
      "train loss:2.268409610747479\n",
      "=== epoch:23, train acc:0.20666666666666667, test acc:0.1584 ===\n",
      "train loss:2.2708439204542237\n",
      "train loss:2.2587487611533668\n",
      "train loss:2.2844570669857465\n",
      "=== epoch:24, train acc:0.21, test acc:0.164 ===\n",
      "train loss:2.2640764837486547\n",
      "train loss:2.256382591985317\n",
      "train loss:2.26439698041261\n",
      "=== epoch:25, train acc:0.21, test acc:0.1646 ===\n",
      "train loss:2.259262791149668\n",
      "train loss:2.2663394321471064\n",
      "train loss:2.2532525006659965\n",
      "=== epoch:26, train acc:0.21, test acc:0.1676 ===\n",
      "train loss:2.2542064156495876\n",
      "train loss:2.256179578958349\n",
      "train loss:2.2634238509662357\n",
      "=== epoch:27, train acc:0.21333333333333335, test acc:0.168 ===\n",
      "train loss:2.244654102625047\n",
      "train loss:2.265507699297373\n",
      "train loss:2.2625123478505045\n",
      "=== epoch:28, train acc:0.22, test acc:0.1761 ===\n",
      "train loss:2.2541496047447116\n",
      "train loss:2.2516566307769037\n",
      "train loss:2.262154598267497\n",
      "=== epoch:29, train acc:0.22, test acc:0.1779 ===\n",
      "train loss:2.256252809302057\n",
      "train loss:2.2474027542970543\n",
      "train loss:2.2578310048985433\n",
      "=== epoch:30, train acc:0.23, test acc:0.1824 ===\n",
      "train loss:2.276691512395534\n",
      "train loss:2.24919103564247\n",
      "train loss:2.2613389062974236\n",
      "=== epoch:31, train acc:0.22666666666666666, test acc:0.1843 ===\n",
      "train loss:2.2605040326085772\n",
      "train loss:2.2517443906833448\n",
      "train loss:2.2612862544347734\n",
      "=== epoch:32, train acc:0.23666666666666666, test acc:0.188 ===\n",
      "train loss:2.255069084857768\n",
      "train loss:2.250583630543724\n",
      "train loss:2.2557043597775173\n",
      "=== epoch:33, train acc:0.24333333333333335, test acc:0.1896 ===\n",
      "train loss:2.2594405958535733\n",
      "train loss:2.256806993672395\n",
      "train loss:2.2501476401084632\n",
      "=== epoch:34, train acc:0.24, test acc:0.1918 ===\n",
      "train loss:2.237698230805246\n",
      "train loss:2.2502773194630263\n",
      "train loss:2.237390863695862\n",
      "=== epoch:35, train acc:0.24333333333333335, test acc:0.1949 ===\n",
      "train loss:2.251268756897597\n",
      "train loss:2.2509877141966075\n",
      "train loss:2.2529179663551653\n",
      "=== epoch:36, train acc:0.24666666666666667, test acc:0.1971 ===\n",
      "train loss:2.2408311525718827\n",
      "train loss:2.260973933567824\n",
      "train loss:2.2539319573392373\n",
      "=== epoch:37, train acc:0.25666666666666665, test acc:0.1992 ===\n",
      "train loss:2.2702636256798137\n",
      "train loss:2.2387959515341267\n",
      "train loss:2.2404505050235435\n",
      "=== epoch:38, train acc:0.24666666666666667, test acc:0.1965 ===\n",
      "train loss:2.249346289463329\n",
      "train loss:2.2502736412065754\n",
      "train loss:2.231264528510435\n",
      "=== epoch:39, train acc:0.24666666666666667, test acc:0.1944 ===\n",
      "train loss:2.2410324259288585\n",
      "train loss:2.2309302534518203\n",
      "train loss:2.2444075683692772\n",
      "=== epoch:40, train acc:0.25333333333333335, test acc:0.1971 ===\n",
      "train loss:2.2461907599948994\n",
      "train loss:2.2611502715502336\n",
      "train loss:2.2238830924228754\n",
      "=== epoch:41, train acc:0.25333333333333335, test acc:0.1993 ===\n",
      "train loss:2.2418610588783014\n",
      "train loss:2.2521783044488997\n",
      "train loss:2.2293271425175907\n",
      "=== epoch:42, train acc:0.24666666666666667, test acc:0.1958 ===\n",
      "train loss:2.2405816033300137\n",
      "train loss:2.2441044937670322\n",
      "train loss:2.223845223881596\n",
      "=== epoch:43, train acc:0.24666666666666667, test acc:0.1979 ===\n",
      "train loss:2.2446162579245175\n",
      "train loss:2.245594448479602\n",
      "train loss:2.23836793541966\n",
      "=== epoch:44, train acc:0.25666666666666665, test acc:0.2044 ===\n",
      "train loss:2.2408966581703367\n",
      "train loss:2.242584615488121\n",
      "train loss:2.2537273882768853\n",
      "=== epoch:45, train acc:0.27, test acc:0.2104 ===\n",
      "train loss:2.2412621465340328\n",
      "train loss:2.2417020263201466\n",
      "train loss:2.229557720721967\n",
      "=== epoch:46, train acc:0.26, test acc:0.2113 ===\n",
      "train loss:2.2292822642204064\n",
      "train loss:2.245753924375153\n",
      "train loss:2.2353983097042995\n",
      "=== epoch:47, train acc:0.26, test acc:0.211 ===\n",
      "train loss:2.2448104582623163\n",
      "train loss:2.225769580182018\n",
      "train loss:2.2270913616857166\n",
      "=== epoch:48, train acc:0.26, test acc:0.212 ===\n",
      "train loss:2.226166367227789\n",
      "train loss:2.2341714508543746\n",
      "train loss:2.235981921654047\n",
      "=== epoch:49, train acc:0.25666666666666665, test acc:0.2107 ===\n",
      "train loss:2.2209382668497146\n",
      "train loss:2.231898747194715\n",
      "train loss:2.220193723602358\n",
      "=== epoch:50, train acc:0.26, test acc:0.2078 ===\n",
      "train loss:2.2232836732508434\n",
      "train loss:2.230605314683983\n",
      "train loss:2.2245464128041323\n",
      "=== epoch:51, train acc:0.25333333333333335, test acc:0.2071 ===\n",
      "train loss:2.2228273555065465\n",
      "train loss:2.2239359523420945\n",
      "train loss:2.219615355783526\n",
      "=== epoch:52, train acc:0.25, test acc:0.2069 ===\n",
      "train loss:2.205310735620172\n",
      "train loss:2.242033381452685\n",
      "train loss:2.2192003221363947\n",
      "=== epoch:53, train acc:0.25, test acc:0.2053 ===\n",
      "train loss:2.231666678177448\n",
      "train loss:2.226664071455966\n",
      "train loss:2.2340195053099245\n",
      "=== epoch:54, train acc:0.25, test acc:0.2102 ===\n",
      "train loss:2.22471359137538\n",
      "train loss:2.220209552785673\n",
      "train loss:2.206311783088005\n",
      "=== epoch:55, train acc:0.24666666666666667, test acc:0.2132 ===\n",
      "train loss:2.2309543229896303\n",
      "train loss:2.2133119688709653\n",
      "train loss:2.2108389217797875\n",
      "=== epoch:56, train acc:0.25, test acc:0.2138 ===\n",
      "train loss:2.2127322170319013\n",
      "train loss:2.2061110777379094\n",
      "train loss:2.226192235993395\n",
      "=== epoch:57, train acc:0.25, test acc:0.2166 ===\n",
      "train loss:2.2276530554846876\n",
      "train loss:2.2217316721352782\n",
      "train loss:2.225877335488271\n",
      "=== epoch:58, train acc:0.25, test acc:0.2165 ===\n",
      "train loss:2.2149260862896343\n",
      "train loss:2.229322369245749\n",
      "train loss:2.206670366635343\n",
      "=== epoch:59, train acc:0.25, test acc:0.2139 ===\n",
      "train loss:2.229762199972406\n",
      "train loss:2.223487712716038\n",
      "train loss:2.1965611018109232\n",
      "=== epoch:60, train acc:0.25, test acc:0.2126 ===\n",
      "train loss:2.1958369092092385\n",
      "train loss:2.2050795595134245\n",
      "train loss:2.2287638818161786\n",
      "=== epoch:61, train acc:0.25666666666666665, test acc:0.2138 ===\n",
      "train loss:2.2152835958630983\n",
      "train loss:2.2068836295581646\n",
      "train loss:2.1998817072998462\n",
      "=== epoch:62, train acc:0.25, test acc:0.2157 ===\n",
      "train loss:2.215566238314856\n",
      "train loss:2.2018247983160566\n",
      "train loss:2.1938049111725597\n",
      "=== epoch:63, train acc:0.24333333333333335, test acc:0.214 ===\n",
      "train loss:2.232855226234702\n",
      "train loss:2.182146616260667\n",
      "train loss:2.2311593519836865\n",
      "=== epoch:64, train acc:0.24666666666666667, test acc:0.2133 ===\n",
      "train loss:2.2241286079938907\n",
      "train loss:2.2059665127193275\n",
      "train loss:2.210367894258033\n",
      "=== epoch:65, train acc:0.25, test acc:0.215 ===\n",
      "train loss:2.2085364038389987\n",
      "train loss:2.229720448505432\n",
      "train loss:2.185871753738154\n",
      "=== epoch:66, train acc:0.24666666666666667, test acc:0.2134 ===\n",
      "train loss:2.1888559668988825\n",
      "train loss:2.1766278804941903\n",
      "train loss:2.178137189979337\n",
      "=== epoch:67, train acc:0.24666666666666667, test acc:0.2146 ===\n",
      "train loss:2.1902448745108454\n",
      "train loss:2.2091945682874123\n",
      "train loss:2.177749272247011\n",
      "=== epoch:68, train acc:0.24333333333333335, test acc:0.2131 ===\n",
      "train loss:2.1993200381220914\n",
      "train loss:2.218099606968394\n",
      "train loss:2.2041471760390166\n",
      "=== epoch:69, train acc:0.25333333333333335, test acc:0.2138 ===\n",
      "train loss:2.2177776517328716\n",
      "train loss:2.184891115455624\n",
      "train loss:2.20481985742795\n",
      "=== epoch:70, train acc:0.25666666666666665, test acc:0.2172 ===\n",
      "train loss:2.1811288107185853\n",
      "train loss:2.19340423036663\n",
      "train loss:2.178763154416391\n",
      "=== epoch:71, train acc:0.2633333333333333, test acc:0.2206 ===\n",
      "train loss:2.2364415542524894\n",
      "train loss:2.203078691904174\n",
      "train loss:2.197471431149247\n",
      "=== epoch:72, train acc:0.2633333333333333, test acc:0.221 ===\n",
      "train loss:2.1912313827830383\n",
      "train loss:2.215467223921678\n",
      "train loss:2.2481047365690454\n",
      "=== epoch:73, train acc:0.2633333333333333, test acc:0.2219 ===\n",
      "train loss:2.193396224898048\n",
      "train loss:2.189570755996883\n",
      "train loss:2.175311535842578\n",
      "=== epoch:74, train acc:0.2633333333333333, test acc:0.2238 ===\n",
      "train loss:2.1898893587084705\n",
      "train loss:2.1731884260629943\n",
      "train loss:2.179987950413515\n",
      "=== epoch:75, train acc:0.26666666666666666, test acc:0.2239 ===\n",
      "train loss:2.225732606353552\n",
      "train loss:2.221611373907598\n",
      "train loss:2.1977221483183063\n",
      "=== epoch:76, train acc:0.29, test acc:0.23 ===\n",
      "train loss:2.1701607439785913\n",
      "train loss:2.1909067317814457\n",
      "train loss:2.2210949163936404\n",
      "=== epoch:77, train acc:0.29333333333333333, test acc:0.2304 ===\n",
      "train loss:2.1799072399967994\n",
      "train loss:2.2006280515942955\n",
      "train loss:2.221678305627284\n",
      "=== epoch:78, train acc:0.3, test acc:0.234 ===\n",
      "train loss:2.167882189023926\n",
      "train loss:2.2116981099596513\n",
      "train loss:2.175793938224221\n",
      "=== epoch:79, train acc:0.2966666666666667, test acc:0.2343 ===\n",
      "train loss:2.1896552901613546\n",
      "train loss:2.1824635016096026\n",
      "train loss:2.180588432688657\n",
      "=== epoch:80, train acc:0.28, test acc:0.2331 ===\n",
      "train loss:2.1769395160159632\n",
      "train loss:2.202343340081806\n",
      "train loss:2.182004916919107\n",
      "=== epoch:81, train acc:0.2833333333333333, test acc:0.2328 ===\n",
      "train loss:2.197536002780819\n",
      "train loss:2.1672400789391473\n",
      "train loss:2.1832328133737047\n",
      "=== epoch:82, train acc:0.2866666666666667, test acc:0.2341 ===\n",
      "train loss:2.166702327359789\n",
      "train loss:2.1962787154773697\n",
      "train loss:2.168543689997202\n",
      "=== epoch:83, train acc:0.29333333333333333, test acc:0.2362 ===\n",
      "train loss:2.168369251138785\n",
      "train loss:2.1720737740408462\n",
      "train loss:2.15950752687131\n",
      "=== epoch:84, train acc:0.29333333333333333, test acc:0.2372 ===\n",
      "train loss:2.1550892768988628\n",
      "train loss:2.1776348145255566\n",
      "train loss:2.2007880713187955\n",
      "=== epoch:85, train acc:0.3, test acc:0.24 ===\n",
      "train loss:2.1546669156897504\n",
      "train loss:2.1453946125934578\n",
      "train loss:2.1680387048216043\n",
      "=== epoch:86, train acc:0.3, test acc:0.2403 ===\n",
      "train loss:2.1368004486455856\n",
      "train loss:2.1537201358345275\n",
      "train loss:2.152273957706803\n",
      "=== epoch:87, train acc:0.3, test acc:0.2401 ===\n",
      "train loss:2.175826989543058\n",
      "train loss:2.2338590986093227\n",
      "train loss:2.159418448276788\n",
      "=== epoch:88, train acc:0.2966666666666667, test acc:0.2413 ===\n",
      "train loss:2.1502312022851346\n",
      "train loss:2.192055259120597\n",
      "train loss:2.171764429231992\n",
      "=== epoch:89, train acc:0.2966666666666667, test acc:0.2416 ===\n",
      "train loss:2.1442954230221427\n",
      "train loss:2.173307718259736\n",
      "train loss:2.178878846996983\n",
      "=== epoch:90, train acc:0.29333333333333333, test acc:0.241 ===\n",
      "train loss:2.15245967418089\n",
      "train loss:2.168416846219325\n",
      "train loss:2.145733855136767\n",
      "=== epoch:91, train acc:0.29333333333333333, test acc:0.2399 ===\n",
      "train loss:2.14195084011713\n",
      "train loss:2.144759129056501\n",
      "train loss:2.151328886116302\n",
      "=== epoch:92, train acc:0.3, test acc:0.2421 ===\n",
      "train loss:2.139161169252474\n",
      "train loss:2.1405391356374754\n",
      "train loss:2.1418716878751027\n",
      "=== epoch:93, train acc:0.30333333333333334, test acc:0.2421 ===\n",
      "train loss:2.158858810259891\n",
      "train loss:2.156868939516908\n",
      "train loss:2.1480839069630577\n",
      "=== epoch:94, train acc:0.30666666666666664, test acc:0.2447 ===\n",
      "train loss:2.1705163078199865\n",
      "train loss:2.1406999048753153\n",
      "train loss:2.171714844968438\n",
      "=== epoch:95, train acc:0.31, test acc:0.2502 ===\n",
      "train loss:2.1562796837713485\n",
      "train loss:2.1441089504238575\n",
      "train loss:2.142593967735226\n",
      "=== epoch:96, train acc:0.31666666666666665, test acc:0.253 ===\n",
      "train loss:2.160852832211604\n",
      "train loss:2.1328789307917515\n",
      "train loss:2.1431055120716582\n",
      "=== epoch:97, train acc:0.32666666666666666, test acc:0.255 ===\n",
      "train loss:2.1382145954228045\n",
      "train loss:2.1344310648668356\n",
      "train loss:2.1555100920879613\n",
      "=== epoch:98, train acc:0.3333333333333333, test acc:0.2558 ===\n",
      "train loss:2.1361055110736946\n",
      "train loss:2.1414356958110283\n",
      "train loss:2.169474309373739\n",
      "=== epoch:99, train acc:0.33, test acc:0.2547 ===\n",
      "train loss:2.1105260531340915\n",
      "train loss:2.1903709117964603\n",
      "train loss:2.128068823629612\n",
      "=== epoch:100, train acc:0.3233333333333333, test acc:0.2541 ===\n",
      "train loss:2.095884657922744\n",
      "train loss:2.1536223257943785\n",
      "train loss:2.1326975572099665\n",
      "=== epoch:101, train acc:0.31333333333333335, test acc:0.2516 ===\n",
      "train loss:2.1148487018347684\n",
      "train loss:2.125579801941058\n",
      "train loss:2.1665733335743576\n",
      "=== epoch:102, train acc:0.31, test acc:0.2533 ===\n",
      "train loss:2.130093692829169\n",
      "train loss:2.1223191425604266\n",
      "train loss:2.058736671190957\n",
      "=== epoch:103, train acc:0.32666666666666666, test acc:0.2535 ===\n",
      "train loss:2.1418692255277874\n",
      "train loss:2.127345623726129\n",
      "train loss:2.1263509949699193\n",
      "=== epoch:104, train acc:0.33666666666666667, test acc:0.2578 ===\n",
      "train loss:2.1517438281468957\n",
      "train loss:2.125101723460901\n",
      "train loss:2.0679143184609616\n",
      "=== epoch:105, train acc:0.3333333333333333, test acc:0.2577 ===\n",
      "train loss:2.1289767789454697\n",
      "train loss:2.115639029175239\n",
      "train loss:2.1263014375391163\n",
      "=== epoch:106, train acc:0.33, test acc:0.2612 ===\n",
      "train loss:2.1379379291854703\n",
      "train loss:2.1058584250080044\n",
      "train loss:2.140048686894255\n",
      "=== epoch:107, train acc:0.32666666666666666, test acc:0.2638 ===\n",
      "train loss:2.1195398447225515\n",
      "train loss:2.1252960985318228\n",
      "train loss:2.1356536473492698\n",
      "=== epoch:108, train acc:0.33, test acc:0.2662 ===\n",
      "train loss:2.062655125187979\n",
      "train loss:2.1812242063846994\n",
      "train loss:2.161114907631728\n",
      "=== epoch:109, train acc:0.33666666666666667, test acc:0.2738 ===\n",
      "train loss:2.106978389964944\n",
      "train loss:2.1049507312354017\n",
      "train loss:2.0571278039821497\n",
      "=== epoch:110, train acc:0.33, test acc:0.2714 ===\n",
      "train loss:2.145660974002711\n",
      "train loss:2.046456500351916\n",
      "train loss:2.1235730758808584\n",
      "=== epoch:111, train acc:0.3466666666666667, test acc:0.2729 ===\n",
      "train loss:2.0959715814694118\n",
      "train loss:2.086968176510092\n",
      "train loss:2.069717977020489\n",
      "=== epoch:112, train acc:0.3466666666666667, test acc:0.2736 ===\n",
      "train loss:2.074460075569023\n",
      "train loss:2.0721651381546122\n",
      "train loss:2.0959069437613844\n",
      "=== epoch:113, train acc:0.34, test acc:0.273 ===\n",
      "train loss:2.1219839816323223\n",
      "train loss:2.1379230626218653\n",
      "train loss:2.1419903784512555\n",
      "=== epoch:114, train acc:0.3466666666666667, test acc:0.2774 ===\n",
      "train loss:2.0968076540508953\n",
      "train loss:2.0862508500491628\n",
      "train loss:2.1010614121351368\n",
      "=== epoch:115, train acc:0.3433333333333333, test acc:0.2772 ===\n",
      "train loss:2.1273104381060337\n",
      "train loss:2.0385180522935613\n",
      "train loss:2.094359134989247\n",
      "=== epoch:116, train acc:0.34, test acc:0.2747 ===\n",
      "train loss:2.0242701683002697\n",
      "train loss:2.096879150496666\n",
      "train loss:2.050955166505864\n",
      "=== epoch:117, train acc:0.3333333333333333, test acc:0.2744 ===\n",
      "train loss:2.1112732243354584\n",
      "train loss:2.0798455800497946\n",
      "train loss:2.1194015753283595\n",
      "=== epoch:118, train acc:0.35, test acc:0.2804 ===\n",
      "train loss:2.049733588577365\n",
      "train loss:2.1122470301300433\n",
      "train loss:2.101915932636459\n",
      "=== epoch:119, train acc:0.35, test acc:0.2843 ===\n",
      "train loss:2.1143531489464022\n",
      "train loss:2.1287609713630093\n",
      "train loss:2.083051363389415\n",
      "=== epoch:120, train acc:0.3566666666666667, test acc:0.2866 ===\n",
      "train loss:2.0976375674900196\n",
      "train loss:2.101228875732705\n",
      "train loss:2.060356858333343\n",
      "=== epoch:121, train acc:0.36, test acc:0.2878 ===\n",
      "train loss:2.089759012761599\n",
      "train loss:2.114416010846397\n",
      "train loss:2.105741669205276\n",
      "=== epoch:122, train acc:0.36, test acc:0.2918 ===\n",
      "train loss:2.0721593817710744\n",
      "train loss:2.037583312197446\n",
      "train loss:2.038824695052524\n",
      "=== epoch:123, train acc:0.36333333333333334, test acc:0.2917 ===\n",
      "train loss:2.092584953613848\n",
      "train loss:2.0448932822384376\n",
      "train loss:2.080435366635568\n",
      "=== epoch:124, train acc:0.37, test acc:0.2923 ===\n",
      "train loss:2.0211121396657457\n",
      "train loss:2.0500169791843432\n",
      "train loss:2.0014821962731544\n",
      "=== epoch:125, train acc:0.36666666666666664, test acc:0.2915 ===\n",
      "train loss:2.024589370370288\n",
      "train loss:2.042983476100103\n",
      "train loss:2.089808952991862\n",
      "=== epoch:126, train acc:0.36333333333333334, test acc:0.2923 ===\n",
      "train loss:2.0672943525781453\n",
      "train loss:2.09010934294984\n",
      "train loss:2.097134389737534\n",
      "=== epoch:127, train acc:0.38, test acc:0.299 ===\n",
      "train loss:2.053560540142596\n",
      "train loss:2.090097656022321\n",
      "train loss:2.136860118946039\n",
      "=== epoch:128, train acc:0.38, test acc:0.3056 ===\n",
      "train loss:2.0336807282017832\n",
      "train loss:2.0863921149782243\n",
      "train loss:2.0573535909776863\n",
      "=== epoch:129, train acc:0.38333333333333336, test acc:0.3072 ===\n",
      "train loss:2.0710004615287754\n",
      "train loss:1.9782346896594933\n",
      "train loss:2.0620015698888525\n",
      "=== epoch:130, train acc:0.38333333333333336, test acc:0.3078 ===\n",
      "train loss:2.0439369170992125\n",
      "train loss:2.080091357339199\n",
      "train loss:2.106637037374033\n",
      "=== epoch:131, train acc:0.37666666666666665, test acc:0.3092 ===\n",
      "train loss:2.0231369452251395\n",
      "train loss:2.0847513770814\n",
      "train loss:1.9948833344979886\n",
      "=== epoch:132, train acc:0.37666666666666665, test acc:0.3076 ===\n",
      "train loss:1.9776140322721532\n",
      "train loss:2.0989517406039\n",
      "train loss:1.9472449096350641\n",
      "=== epoch:133, train acc:0.37666666666666665, test acc:0.3046 ===\n",
      "train loss:2.043933671237235\n",
      "train loss:2.046569920078474\n",
      "train loss:2.045714061822771\n",
      "=== epoch:134, train acc:0.38, test acc:0.3075 ===\n",
      "train loss:2.0033158288491117\n",
      "train loss:2.0015319315906224\n",
      "train loss:2.0513278625582374\n",
      "=== epoch:135, train acc:0.37666666666666665, test acc:0.306 ===\n",
      "train loss:2.04434415023452\n",
      "train loss:1.9260863256004432\n",
      "train loss:2.0343640434062427\n",
      "=== epoch:136, train acc:0.37666666666666665, test acc:0.3046 ===\n",
      "train loss:2.047428384965867\n",
      "train loss:2.0108403500187277\n",
      "train loss:1.988081027164934\n",
      "=== epoch:137, train acc:0.37666666666666665, test acc:0.3064 ===\n",
      "train loss:2.056612274942097\n",
      "train loss:1.9889037314779987\n",
      "train loss:1.9985630882783953\n",
      "=== epoch:138, train acc:0.37666666666666665, test acc:0.3069 ===\n",
      "train loss:2.0247790664276106\n",
      "train loss:1.9979044013209495\n",
      "train loss:1.965220712850006\n",
      "=== epoch:139, train acc:0.37666666666666665, test acc:0.3074 ===\n",
      "train loss:1.9123077262227173\n",
      "train loss:1.9713743177556227\n",
      "train loss:2.073106910964332\n",
      "=== epoch:140, train acc:0.38666666666666666, test acc:0.3079 ===\n",
      "train loss:1.977275852622003\n",
      "train loss:2.0043556078737375\n",
      "train loss:1.93187867061271\n",
      "=== epoch:141, train acc:0.39, test acc:0.3087 ===\n",
      "train loss:2.070957843578142\n",
      "train loss:1.9897104914758816\n",
      "train loss:1.9393602083695647\n",
      "=== epoch:142, train acc:0.4033333333333333, test acc:0.313 ===\n",
      "train loss:2.0383162097797403\n",
      "train loss:2.015256500418227\n",
      "train loss:2.005879200781733\n",
      "=== epoch:143, train acc:0.4, test acc:0.3131 ===\n",
      "train loss:2.0111155422003706\n",
      "train loss:1.9976006678816676\n",
      "train loss:2.030196810412994\n",
      "=== epoch:144, train acc:0.3933333333333333, test acc:0.3163 ===\n",
      "train loss:1.9198933494324146\n",
      "train loss:1.9977308509079332\n",
      "train loss:2.01616188415997\n",
      "=== epoch:145, train acc:0.4, test acc:0.3194 ===\n",
      "train loss:1.8664916021473508\n",
      "train loss:1.992401160520785\n",
      "train loss:2.064507956716236\n",
      "=== epoch:146, train acc:0.39666666666666667, test acc:0.3237 ===\n",
      "train loss:1.8539246968148684\n",
      "train loss:1.9001270094639033\n",
      "train loss:1.8282092167422255\n",
      "=== epoch:147, train acc:0.3933333333333333, test acc:0.3199 ===\n",
      "train loss:1.9549351322576718\n",
      "train loss:2.0289432452642697\n",
      "train loss:1.9400682831537532\n",
      "=== epoch:148, train acc:0.4, test acc:0.3261 ===\n",
      "train loss:2.0334815202611263\n",
      "train loss:1.8772452647895128\n",
      "train loss:1.9936153335699935\n",
      "=== epoch:149, train acc:0.4033333333333333, test acc:0.3253 ===\n",
      "train loss:2.0009222490138345\n",
      "train loss:1.9644453779779718\n",
      "train loss:1.967052072152779\n",
      "=== epoch:150, train acc:0.4033333333333333, test acc:0.3282 ===\n",
      "train loss:1.9783642760327718\n",
      "train loss:1.8607093335658058\n",
      "train loss:1.8994856974110774\n",
      "=== epoch:151, train acc:0.4033333333333333, test acc:0.3309 ===\n",
      "train loss:1.9935627214582157\n",
      "train loss:1.9916293340109203\n",
      "train loss:1.975099019234579\n",
      "=== epoch:152, train acc:0.41, test acc:0.3339 ===\n",
      "train loss:1.8680477827394606\n",
      "train loss:1.9506835983409148\n",
      "train loss:1.9888890698548451\n",
      "=== epoch:153, train acc:0.41, test acc:0.3354 ===\n",
      "train loss:1.9950626695620455\n",
      "train loss:1.9863853315006572\n",
      "train loss:2.008699119765699\n",
      "=== epoch:154, train acc:0.4066666666666667, test acc:0.3415 ===\n",
      "train loss:1.9497476290541251\n",
      "train loss:1.985883163371882\n",
      "train loss:1.905398579430047\n",
      "=== epoch:155, train acc:0.4066666666666667, test acc:0.3407 ===\n",
      "train loss:1.9376505971305193\n",
      "train loss:1.8865332320314103\n",
      "train loss:1.9023825932680374\n",
      "=== epoch:156, train acc:0.41333333333333333, test acc:0.3415 ===\n",
      "train loss:1.8986183969403712\n",
      "train loss:1.8837367578307078\n",
      "train loss:1.9827083057853643\n",
      "=== epoch:157, train acc:0.41, test acc:0.341 ===\n",
      "train loss:1.9465925559571418\n",
      "train loss:1.799816655060329\n",
      "train loss:1.852340026579818\n",
      "=== epoch:158, train acc:0.41, test acc:0.3402 ===\n",
      "train loss:1.9168112294418085\n",
      "train loss:1.9141609553842542\n",
      "train loss:1.8738792088509941\n",
      "=== epoch:159, train acc:0.4166666666666667, test acc:0.3412 ===\n",
      "train loss:1.8997291539981467\n",
      "train loss:1.89495023975926\n",
      "train loss:1.8611902245546306\n",
      "=== epoch:160, train acc:0.4166666666666667, test acc:0.3395 ===\n",
      "train loss:1.9709414395234233\n",
      "train loss:1.8094191736041654\n",
      "train loss:1.9001955774065755\n",
      "=== epoch:161, train acc:0.4166666666666667, test acc:0.3454 ===\n",
      "train loss:1.9291610251306879\n",
      "train loss:1.9395148011045444\n",
      "train loss:1.8192304499694834\n",
      "=== epoch:162, train acc:0.42, test acc:0.3457 ===\n",
      "train loss:1.874190144617662\n",
      "train loss:1.8877424601326909\n",
      "train loss:1.884744158845782\n",
      "=== epoch:163, train acc:0.4266666666666667, test acc:0.349 ===\n",
      "train loss:1.9220419042841252\n",
      "train loss:1.8687418502106516\n",
      "train loss:1.9676064898430021\n",
      "=== epoch:164, train acc:0.42333333333333334, test acc:0.3511 ===\n",
      "train loss:1.964312920504444\n",
      "train loss:1.8300761633254279\n",
      "train loss:1.896488874051185\n",
      "=== epoch:165, train acc:0.43, test acc:0.3522 ===\n",
      "train loss:1.925489330924819\n",
      "train loss:1.8599621866146316\n",
      "train loss:1.8294883084583566\n",
      "=== epoch:166, train acc:0.43, test acc:0.3523 ===\n",
      "train loss:1.8265667638295215\n",
      "train loss:1.7751271331726832\n",
      "train loss:1.913109183081941\n",
      "=== epoch:167, train acc:0.43, test acc:0.3556 ===\n",
      "train loss:1.8258464560117913\n",
      "train loss:1.8106635776639382\n",
      "train loss:1.866302790684891\n",
      "=== epoch:168, train acc:0.43, test acc:0.355 ===\n",
      "train loss:1.9124523076243394\n",
      "train loss:1.8624169393096304\n",
      "train loss:1.8624280177027182\n",
      "=== epoch:169, train acc:0.43333333333333335, test acc:0.3576 ===\n",
      "train loss:1.9187353822773519\n",
      "train loss:1.8561688562421614\n",
      "train loss:1.804279117248478\n",
      "=== epoch:170, train acc:0.43666666666666665, test acc:0.3601 ===\n",
      "train loss:1.8812605088890713\n",
      "train loss:1.8203744067645027\n",
      "train loss:1.797147421473297\n",
      "=== epoch:171, train acc:0.43, test acc:0.3615 ===\n",
      "train loss:1.758863558488169\n",
      "train loss:1.8515319979082698\n",
      "train loss:1.8183425711643508\n",
      "=== epoch:172, train acc:0.43333333333333335, test acc:0.3626 ===\n",
      "train loss:1.9817865121299219\n",
      "train loss:1.7654726287792248\n",
      "train loss:1.754082359003553\n",
      "=== epoch:173, train acc:0.4266666666666667, test acc:0.3619 ===\n",
      "train loss:1.8626461411595958\n",
      "train loss:1.8061834579763174\n",
      "train loss:1.6571199282590117\n",
      "=== epoch:174, train acc:0.43333333333333335, test acc:0.3597 ===\n",
      "train loss:1.8183769127004228\n",
      "train loss:1.8497895494692371\n",
      "train loss:1.9099513742123435\n",
      "=== epoch:175, train acc:0.44333333333333336, test acc:0.3648 ===\n",
      "train loss:1.867866669770967\n",
      "train loss:1.886163392362556\n",
      "train loss:1.8383704964954166\n",
      "=== epoch:176, train acc:0.44666666666666666, test acc:0.3731 ===\n",
      "train loss:1.88376847429188\n",
      "train loss:1.7613858802548683\n",
      "train loss:1.8850084560738427\n",
      "=== epoch:177, train acc:0.44, test acc:0.3726 ===\n",
      "train loss:1.7682178743501737\n",
      "train loss:1.8215362261013508\n",
      "train loss:1.735425329424135\n",
      "=== epoch:178, train acc:0.44333333333333336, test acc:0.3689 ===\n",
      "train loss:1.8819894841177045\n",
      "train loss:1.7027044895240484\n",
      "train loss:1.8902409001981002\n",
      "=== epoch:179, train acc:0.44666666666666666, test acc:0.3686 ===\n",
      "train loss:1.7728298969767775\n",
      "train loss:1.7495587776717678\n",
      "train loss:1.7307531853301297\n",
      "=== epoch:180, train acc:0.44333333333333336, test acc:0.367 ===\n",
      "train loss:1.727018645993081\n",
      "train loss:1.8027531308577593\n",
      "train loss:1.764435059712475\n",
      "=== epoch:181, train acc:0.44, test acc:0.3689 ===\n",
      "train loss:1.8250303501674796\n",
      "train loss:1.715273183114638\n",
      "train loss:1.7586597672777031\n",
      "=== epoch:182, train acc:0.45, test acc:0.3706 ===\n",
      "train loss:1.7562099526460684\n",
      "train loss:1.8360318591369884\n",
      "train loss:1.7637240687946\n",
      "=== epoch:183, train acc:0.44666666666666666, test acc:0.3719 ===\n",
      "train loss:1.6897560469302826\n",
      "train loss:1.7786468265078696\n",
      "train loss:1.7583070937997116\n",
      "=== epoch:184, train acc:0.45, test acc:0.3733 ===\n",
      "train loss:1.7301271110289904\n",
      "train loss:1.7431928113034316\n",
      "train loss:1.8345327280604289\n",
      "=== epoch:185, train acc:0.45, test acc:0.3751 ===\n",
      "train loss:1.6894919024730235\n",
      "train loss:1.7725372323847333\n",
      "train loss:1.7775931860897274\n",
      "=== epoch:186, train acc:0.44333333333333336, test acc:0.3772 ===\n",
      "train loss:1.667692394001472\n",
      "train loss:1.8221752624003107\n",
      "train loss:1.663767481566537\n",
      "=== epoch:187, train acc:0.45, test acc:0.3788 ===\n",
      "train loss:1.6668276707227039\n",
      "train loss:1.743254365609375\n",
      "train loss:1.682305399094311\n",
      "=== epoch:188, train acc:0.45, test acc:0.3788 ===\n",
      "train loss:1.688938277407734\n",
      "train loss:1.7464519474730265\n",
      "train loss:1.6533014142913087\n",
      "=== epoch:189, train acc:0.44666666666666666, test acc:0.3756 ===\n",
      "train loss:1.646474278929244\n",
      "train loss:1.7222689241287636\n",
      "train loss:1.722584913406083\n",
      "=== epoch:190, train acc:0.44333333333333336, test acc:0.3757 ===\n",
      "train loss:1.773991075798677\n",
      "train loss:1.6529566894389591\n",
      "train loss:1.6494108120784237\n",
      "=== epoch:191, train acc:0.45, test acc:0.3785 ===\n",
      "train loss:1.6495218824552274\n",
      "train loss:1.7835579454955348\n",
      "train loss:1.7424154000306282\n",
      "=== epoch:192, train acc:0.45666666666666667, test acc:0.3796 ===\n",
      "train loss:1.755496327305063\n",
      "train loss:1.8124898715585938\n",
      "train loss:1.6446632533029197\n",
      "=== epoch:193, train acc:0.45, test acc:0.3785 ===\n",
      "train loss:1.6596724466946136\n",
      "train loss:1.7343970736835712\n",
      "train loss:1.622744711136372\n",
      "=== epoch:194, train acc:0.44666666666666666, test acc:0.3787 ===\n",
      "train loss:1.7355397534661097\n",
      "train loss:1.6453040990032657\n",
      "train loss:1.6886022008916566\n",
      "=== epoch:195, train acc:0.45666666666666667, test acc:0.3807 ===\n",
      "train loss:1.7875961246866823\n",
      "train loss:1.758413953744973\n",
      "train loss:1.6995498548138368\n",
      "=== epoch:196, train acc:0.45, test acc:0.3836 ===\n",
      "train loss:1.7453840438128745\n",
      "train loss:1.666028071154824\n",
      "train loss:1.7570151741359552\n",
      "=== epoch:197, train acc:0.45666666666666667, test acc:0.3865 ===\n",
      "train loss:1.7255356142653246\n",
      "train loss:1.6391865470956928\n",
      "train loss:1.6994088358110222\n",
      "=== epoch:198, train acc:0.45666666666666667, test acc:0.3873 ===\n",
      "train loss:1.719834070806557\n",
      "train loss:1.6837939783606097\n",
      "train loss:1.7592811917871922\n",
      "=== epoch:199, train acc:0.47, test acc:0.3882 ===\n",
      "train loss:1.6118859251232842\n",
      "train loss:1.6248429598109928\n",
      "train loss:1.7060902059698366\n",
      "=== epoch:200, train acc:0.45666666666666667, test acc:0.3901 ===\n",
      "train loss:1.6135120540125831\n",
      "train loss:1.63084628265506\n",
      "train loss:1.6041984834404894\n",
      "=== epoch:201, train acc:0.4533333333333333, test acc:0.3902 ===\n",
      "train loss:1.6328815769796123\n",
      "train loss:1.6184058064852211\n",
      "train loss:1.7870687399357843\n",
      "=== epoch:202, train acc:0.4533333333333333, test acc:0.3912 ===\n",
      "train loss:1.643254454327029\n",
      "train loss:1.6547175871266475\n",
      "train loss:1.7444582985415837\n",
      "=== epoch:203, train acc:0.45666666666666667, test acc:0.3956 ===\n",
      "train loss:1.6883532142207651\n",
      "train loss:1.608932216972739\n",
      "train loss:1.6205691070605526\n",
      "=== epoch:204, train acc:0.45666666666666667, test acc:0.3924 ===\n",
      "train loss:1.7626118856456672\n",
      "train loss:1.6046884653123359\n",
      "train loss:1.7651441812596484\n",
      "=== epoch:205, train acc:0.46, test acc:0.3918 ===\n",
      "train loss:1.6398290172342476\n",
      "train loss:1.8202413998683684\n",
      "train loss:1.7738520875343726\n",
      "=== epoch:206, train acc:0.4666666666666667, test acc:0.3958 ===\n",
      "train loss:1.6629817130146916\n",
      "train loss:1.6199483938316523\n",
      "train loss:1.692340496851095\n",
      "=== epoch:207, train acc:0.4666666666666667, test acc:0.3932 ===\n",
      "train loss:1.6515429135613693\n",
      "train loss:1.7270042276458406\n",
      "train loss:1.6136570281853861\n",
      "=== epoch:208, train acc:0.47333333333333333, test acc:0.3946 ===\n",
      "train loss:1.6184403477392184\n",
      "train loss:1.6925562803051495\n",
      "train loss:1.6742399599043896\n",
      "=== epoch:209, train acc:0.47, test acc:0.3922 ===\n",
      "train loss:1.591044592938831\n",
      "train loss:1.7053992938374818\n",
      "train loss:1.6488472286139912\n",
      "=== epoch:210, train acc:0.47333333333333333, test acc:0.3932 ===\n",
      "train loss:1.6305760913506493\n",
      "train loss:1.6767709709440655\n",
      "train loss:1.6443944356479878\n",
      "=== epoch:211, train acc:0.47333333333333333, test acc:0.3997 ===\n",
      "train loss:1.5149438122405883\n",
      "train loss:1.6270024626555637\n",
      "train loss:1.713242180718688\n",
      "=== epoch:212, train acc:0.4766666666666667, test acc:0.4011 ===\n",
      "train loss:1.6309884158254897\n",
      "train loss:1.6817100734412114\n",
      "train loss:1.4731474371197757\n",
      "=== epoch:213, train acc:0.4766666666666667, test acc:0.4021 ===\n",
      "train loss:1.5647796599448045\n",
      "train loss:1.542003283750635\n",
      "train loss:1.5697465171909357\n",
      "=== epoch:214, train acc:0.4766666666666667, test acc:0.4046 ===\n",
      "train loss:1.60972945491132\n",
      "train loss:1.510143568225656\n",
      "train loss:1.6083137210176417\n",
      "=== epoch:215, train acc:0.48, test acc:0.4073 ===\n",
      "train loss:1.644188337000608\n",
      "train loss:1.423524411028626\n",
      "train loss:1.3462659261088277\n",
      "=== epoch:216, train acc:0.47333333333333333, test acc:0.4066 ===\n",
      "train loss:1.5805385297961496\n",
      "train loss:1.632404192412565\n",
      "train loss:1.6683234760009102\n",
      "=== epoch:217, train acc:0.48, test acc:0.4093 ===\n",
      "train loss:1.5187713789425485\n",
      "train loss:1.4801477691016038\n",
      "train loss:1.5901589153027427\n",
      "=== epoch:218, train acc:0.48333333333333334, test acc:0.4062 ===\n",
      "train loss:1.5784101821520897\n",
      "train loss:1.4776891188348709\n",
      "train loss:1.6403656178881432\n",
      "=== epoch:219, train acc:0.4866666666666667, test acc:0.4088 ===\n",
      "train loss:1.5191478715026512\n",
      "train loss:1.625509139591417\n",
      "train loss:1.408988281174458\n",
      "=== epoch:220, train acc:0.49, test acc:0.4095 ===\n",
      "train loss:1.6218768592864226\n",
      "train loss:1.6571214612091218\n",
      "train loss:1.4967940413485192\n",
      "=== epoch:221, train acc:0.49, test acc:0.4123 ===\n",
      "train loss:1.5680721897153918\n",
      "train loss:1.6076187814568903\n",
      "train loss:1.489715980680204\n",
      "=== epoch:222, train acc:0.48333333333333334, test acc:0.412 ===\n",
      "train loss:1.532937787167029\n",
      "train loss:1.6178716912571034\n",
      "train loss:1.5933074126255589\n",
      "=== epoch:223, train acc:0.49, test acc:0.4148 ===\n",
      "train loss:1.6151787603946894\n",
      "train loss:1.5242579552528315\n",
      "train loss:1.5152719547457747\n",
      "=== epoch:224, train acc:0.49666666666666665, test acc:0.4148 ===\n",
      "train loss:1.5515761180884886\n",
      "train loss:1.6395736792622797\n",
      "train loss:1.5763491232346496\n",
      "=== epoch:225, train acc:0.49333333333333335, test acc:0.4155 ===\n",
      "train loss:1.561478153295499\n",
      "train loss:1.5685939846510013\n",
      "train loss:1.5538243882742306\n",
      "=== epoch:226, train acc:0.5033333333333333, test acc:0.417 ===\n",
      "train loss:1.6342508372636433\n",
      "train loss:1.5938817406786085\n",
      "train loss:1.460036220726021\n",
      "=== epoch:227, train acc:0.5033333333333333, test acc:0.4184 ===\n",
      "train loss:1.5812290491341658\n",
      "train loss:1.5508815660894475\n",
      "train loss:1.5534712923515572\n",
      "=== epoch:228, train acc:0.5066666666666667, test acc:0.4213 ===\n",
      "train loss:1.5860017493633045\n",
      "train loss:1.4888171197186353\n",
      "train loss:1.5432150385141403\n",
      "=== epoch:229, train acc:0.51, test acc:0.4245 ===\n",
      "train loss:1.5203603873088027\n",
      "train loss:1.5495198138757929\n",
      "train loss:1.5976477856806672\n",
      "=== epoch:230, train acc:0.5133333333333333, test acc:0.4264 ===\n",
      "train loss:1.5172602973918732\n",
      "train loss:1.4794349575177403\n",
      "train loss:1.536194626423789\n",
      "=== epoch:231, train acc:0.5266666666666666, test acc:0.4289 ===\n",
      "train loss:1.6818065722342153\n",
      "train loss:1.4455759927915144\n",
      "train loss:1.5539368155083884\n",
      "=== epoch:232, train acc:0.5233333333333333, test acc:0.4311 ===\n",
      "train loss:1.4581174190159816\n",
      "train loss:1.39121079400697\n",
      "train loss:1.4894652116914853\n",
      "=== epoch:233, train acc:0.53, test acc:0.4319 ===\n",
      "train loss:1.4649470736697685\n",
      "train loss:1.5179018920367375\n",
      "train loss:1.4088722799779427\n",
      "=== epoch:234, train acc:0.5233333333333333, test acc:0.4333 ===\n",
      "train loss:1.5323479571854122\n",
      "train loss:1.3875748709565436\n",
      "train loss:1.4624310028899328\n",
      "=== epoch:235, train acc:0.53, test acc:0.4358 ===\n",
      "train loss:1.4772422666065497\n",
      "train loss:1.5910276401469914\n",
      "train loss:1.5065116767178197\n",
      "=== epoch:236, train acc:0.5366666666666666, test acc:0.4351 ===\n",
      "train loss:1.3899233310793182\n",
      "train loss:1.501427117083513\n",
      "train loss:1.5848446680376091\n",
      "=== epoch:237, train acc:0.55, test acc:0.4364 ===\n",
      "train loss:1.395640548022635\n",
      "train loss:1.487727640874542\n",
      "train loss:1.5187159311594474\n",
      "=== epoch:238, train acc:0.5466666666666666, test acc:0.4369 ===\n",
      "train loss:1.3736833776026875\n",
      "train loss:1.5063984065768117\n",
      "train loss:1.3718732041334585\n",
      "=== epoch:239, train acc:0.5433333333333333, test acc:0.437 ===\n",
      "train loss:1.396229472654596\n",
      "train loss:1.4035174204978675\n",
      "train loss:1.4517427354353702\n",
      "=== epoch:240, train acc:0.53, test acc:0.4386 ===\n",
      "train loss:1.4926498076892412\n",
      "train loss:1.4078916012434866\n",
      "train loss:1.4115944983858986\n",
      "=== epoch:241, train acc:0.55, test acc:0.4363 ===\n",
      "train loss:1.4465115237706834\n",
      "train loss:1.4528197396330418\n",
      "train loss:1.4511100511413024\n",
      "=== epoch:242, train acc:0.5466666666666666, test acc:0.4412 ===\n",
      "train loss:1.4759948744143288\n",
      "train loss:1.4958809475670691\n",
      "train loss:1.4520345745583016\n",
      "=== epoch:243, train acc:0.55, test acc:0.4424 ===\n",
      "train loss:1.5012113794844026\n",
      "train loss:1.3917834645636018\n",
      "train loss:1.4077884099058988\n",
      "=== epoch:244, train acc:0.55, test acc:0.4453 ===\n",
      "train loss:1.447982982316517\n",
      "train loss:1.2511576706402914\n",
      "train loss:1.3356201315667398\n",
      "=== epoch:245, train acc:0.5633333333333334, test acc:0.4453 ===\n",
      "train loss:1.4912198544400281\n",
      "train loss:1.3536341460951622\n",
      "train loss:1.304888270555381\n",
      "=== epoch:246, train acc:0.56, test acc:0.4432 ===\n",
      "train loss:1.437370162824357\n",
      "train loss:1.4482637555643376\n",
      "train loss:1.5036928316445222\n",
      "=== epoch:247, train acc:0.57, test acc:0.4459 ===\n",
      "train loss:1.4030295966443713\n",
      "train loss:1.2439327693965447\n",
      "train loss:1.3299719421139935\n",
      "=== epoch:248, train acc:0.5766666666666667, test acc:0.4465 ===\n",
      "train loss:1.351491166946537\n",
      "train loss:1.3176658268375925\n",
      "train loss:1.3365880878446625\n",
      "=== epoch:249, train acc:0.5666666666666667, test acc:0.4453 ===\n",
      "train loss:1.4192127160936423\n",
      "train loss:1.4476697511911185\n",
      "train loss:1.400562059361357\n",
      "=== epoch:250, train acc:0.56, test acc:0.4489 ===\n",
      "train loss:1.4253896566955424\n",
      "train loss:1.3646280516673948\n",
      "train loss:1.3435411778828006\n",
      "=== epoch:251, train acc:0.5733333333333334, test acc:0.4496 ===\n",
      "train loss:1.4867156679493414\n",
      "train loss:1.3970240887355347\n",
      "train loss:1.3540449223641349\n",
      "=== epoch:252, train acc:0.5733333333333334, test acc:0.4504 ===\n",
      "train loss:1.366429288396495\n",
      "train loss:1.2491444717726068\n",
      "train loss:1.3994129901946666\n",
      "=== epoch:253, train acc:0.57, test acc:0.4497 ===\n",
      "train loss:1.3373681184451394\n",
      "train loss:1.3064502227068204\n",
      "train loss:1.328193289405536\n",
      "=== epoch:254, train acc:0.5733333333333334, test acc:0.4519 ===\n",
      "train loss:1.3623555985293976\n",
      "train loss:1.2479750050516338\n",
      "train loss:1.3377162291014335\n",
      "=== epoch:255, train acc:0.5733333333333334, test acc:0.455 ===\n",
      "train loss:1.3333719323266096\n",
      "train loss:1.324179727344364\n",
      "train loss:1.3251824495449258\n",
      "=== epoch:256, train acc:0.5766666666666667, test acc:0.4572 ===\n",
      "train loss:1.2636258306189112\n",
      "train loss:1.359811741759665\n",
      "train loss:1.3839336566971685\n",
      "=== epoch:257, train acc:0.56, test acc:0.4587 ===\n",
      "train loss:1.4703237137182072\n",
      "train loss:1.2602830723014504\n",
      "train loss:1.2612588861669216\n",
      "=== epoch:258, train acc:0.5633333333333334, test acc:0.4587 ===\n",
      "train loss:1.365220389255547\n",
      "train loss:1.413321048358516\n",
      "train loss:1.2611409736552068\n",
      "=== epoch:259, train acc:0.57, test acc:0.4613 ===\n",
      "train loss:1.3429030485564704\n",
      "train loss:1.3154376091644506\n",
      "train loss:1.338674880540688\n",
      "=== epoch:260, train acc:0.5933333333333334, test acc:0.4617 ===\n",
      "train loss:1.388774808662967\n",
      "train loss:1.4153962261135227\n",
      "train loss:1.349663281200726\n",
      "=== epoch:261, train acc:0.5833333333333334, test acc:0.4687 ===\n",
      "train loss:1.2836301075188459\n",
      "train loss:1.2647453694861912\n",
      "train loss:1.2451322465039865\n",
      "=== epoch:262, train acc:0.5933333333333334, test acc:0.4679 ===\n",
      "train loss:1.2876367445924044\n",
      "train loss:1.3249630295720505\n",
      "train loss:1.1326413423320536\n",
      "=== epoch:263, train acc:0.5966666666666667, test acc:0.4706 ===\n",
      "train loss:1.455120374533031\n",
      "train loss:1.3333489346783336\n",
      "train loss:1.2433757123505618\n",
      "=== epoch:264, train acc:0.6, test acc:0.4715 ===\n",
      "train loss:1.2461130902694468\n",
      "train loss:1.1928054430693262\n",
      "train loss:1.2648565232854176\n",
      "=== epoch:265, train acc:0.6, test acc:0.4711 ===\n",
      "train loss:1.1289844093905252\n",
      "train loss:1.3613430829874966\n",
      "train loss:1.2095146766304463\n",
      "=== epoch:266, train acc:0.5966666666666667, test acc:0.4718 ===\n",
      "train loss:1.4074064958835857\n",
      "train loss:1.3129544804467514\n",
      "train loss:1.2564987812923611\n",
      "=== epoch:267, train acc:0.6033333333333334, test acc:0.4742 ===\n",
      "train loss:1.11552025435541\n",
      "train loss:1.4085477852659198\n",
      "train loss:1.2515718949445063\n",
      "=== epoch:268, train acc:0.6033333333333334, test acc:0.4744 ===\n",
      "train loss:1.3166986873732063\n",
      "train loss:1.2693811847143186\n",
      "train loss:1.2018060438792157\n",
      "=== epoch:269, train acc:0.6066666666666667, test acc:0.48 ===\n",
      "train loss:1.2181294239828833\n",
      "train loss:1.2569182756246302\n",
      "train loss:1.222411503923861\n",
      "=== epoch:270, train acc:0.6033333333333334, test acc:0.4825 ===\n",
      "train loss:1.3076356129215594\n",
      "train loss:1.3177523467587935\n",
      "train loss:1.2580571366283044\n",
      "=== epoch:271, train acc:0.62, test acc:0.4825 ===\n",
      "train loss:1.3129940830974391\n",
      "train loss:1.2022322312365548\n",
      "train loss:1.2494979600282843\n",
      "=== epoch:272, train acc:0.62, test acc:0.4855 ===\n",
      "train loss:1.2910629224183625\n",
      "train loss:1.244437787267526\n",
      "train loss:1.4150340616124766\n",
      "=== epoch:273, train acc:0.62, test acc:0.4889 ===\n",
      "train loss:1.2399197112064626\n",
      "train loss:1.205362562725731\n",
      "train loss:1.2353296436757863\n",
      "=== epoch:274, train acc:0.6166666666666667, test acc:0.4901 ===\n",
      "train loss:1.3398179005972666\n",
      "train loss:1.3202280265517146\n",
      "train loss:1.250767570956448\n",
      "=== epoch:275, train acc:0.6233333333333333, test acc:0.4906 ===\n",
      "train loss:1.1643059716157957\n",
      "train loss:1.3044613578863746\n",
      "train loss:1.2309523243392606\n",
      "=== epoch:276, train acc:0.6266666666666667, test acc:0.4928 ===\n",
      "train loss:1.1906662634001692\n",
      "train loss:1.2273095951609017\n",
      "train loss:1.303587595893046\n",
      "=== epoch:277, train acc:0.6233333333333333, test acc:0.4912 ===\n",
      "train loss:1.2310622743141737\n",
      "train loss:1.265608123251143\n",
      "train loss:1.1786399406489658\n",
      "=== epoch:278, train acc:0.6233333333333333, test acc:0.4938 ===\n",
      "train loss:1.1213390664538216\n",
      "train loss:1.2432923040092114\n",
      "train loss:1.2213842871573752\n",
      "=== epoch:279, train acc:0.63, test acc:0.4929 ===\n",
      "train loss:1.005425986153237\n",
      "train loss:1.123017957371443\n",
      "train loss:1.2035150722496304\n",
      "=== epoch:280, train acc:0.6233333333333333, test acc:0.4937 ===\n",
      "train loss:1.1441413438964678\n",
      "train loss:1.1796907429191759\n",
      "train loss:1.2458441644677587\n",
      "=== epoch:281, train acc:0.6333333333333333, test acc:0.4948 ===\n",
      "train loss:1.1703587609993362\n",
      "train loss:1.2974448122233633\n",
      "train loss:1.1750652994969273\n",
      "=== epoch:282, train acc:0.6366666666666667, test acc:0.4982 ===\n",
      "train loss:1.113401241227818\n",
      "train loss:1.177478253677407\n",
      "train loss:1.2097100098410223\n",
      "=== epoch:283, train acc:0.63, test acc:0.4969 ===\n",
      "train loss:1.319207925978312\n",
      "train loss:1.101581456343401\n",
      "train loss:1.0458519949207523\n",
      "=== epoch:284, train acc:0.64, test acc:0.5006 ===\n",
      "train loss:1.163374601509948\n",
      "train loss:1.1031338196771363\n",
      "train loss:1.1530269338334522\n",
      "=== epoch:285, train acc:0.6366666666666667, test acc:0.5004 ===\n",
      "train loss:1.2815547065061208\n",
      "train loss:1.067905608472922\n",
      "train loss:1.22125895629038\n",
      "=== epoch:286, train acc:0.6266666666666667, test acc:0.502 ===\n",
      "train loss:1.1365314721346873\n",
      "train loss:1.2976037513496648\n",
      "train loss:1.3014733919694976\n",
      "=== epoch:287, train acc:0.63, test acc:0.5027 ===\n",
      "train loss:1.0720760067991952\n",
      "train loss:1.0613387842006738\n",
      "train loss:1.1479847169236377\n",
      "=== epoch:288, train acc:0.6366666666666667, test acc:0.5017 ===\n",
      "train loss:1.0639681640357896\n",
      "train loss:1.310418408128461\n",
      "train loss:1.1733806917679226\n",
      "=== epoch:289, train acc:0.6433333333333333, test acc:0.5026 ===\n",
      "train loss:1.1702882236960197\n",
      "train loss:1.1839091592421656\n",
      "train loss:1.1259919296759562\n",
      "=== epoch:290, train acc:0.6533333333333333, test acc:0.5068 ===\n",
      "train loss:1.0980955904243945\n",
      "train loss:1.0860678037881373\n",
      "train loss:1.2362695221587443\n",
      "=== epoch:291, train acc:0.6433333333333333, test acc:0.5071 ===\n",
      "train loss:1.0441857249361168\n",
      "train loss:1.1927231476861266\n",
      "train loss:1.1191098970217068\n",
      "=== epoch:292, train acc:0.64, test acc:0.5057 ===\n",
      "train loss:1.1112397742053728\n",
      "train loss:0.9780212302099153\n",
      "train loss:1.1331182448115693\n",
      "=== epoch:293, train acc:0.6433333333333333, test acc:0.5035 ===\n",
      "train loss:1.1830822004873136\n",
      "train loss:1.1848806929838045\n",
      "train loss:1.0981533557127559\n",
      "=== epoch:294, train acc:0.6466666666666666, test acc:0.5035 ===\n",
      "train loss:1.2602307727275157\n",
      "train loss:1.1427803870037538\n",
      "train loss:1.1773114965773945\n",
      "=== epoch:295, train acc:0.6433333333333333, test acc:0.5082 ===\n",
      "train loss:1.1051508567770112\n",
      "train loss:1.0859165710582426\n",
      "train loss:1.1363236200200415\n",
      "=== epoch:296, train acc:0.6666666666666666, test acc:0.5095 ===\n",
      "train loss:1.1310723732780914\n",
      "train loss:1.2248985909424388\n",
      "train loss:1.0677438348452544\n",
      "=== epoch:297, train acc:0.66, test acc:0.5101 ===\n",
      "train loss:1.0542779362179755\n",
      "train loss:1.1254260339345619\n",
      "train loss:1.0885747147008535\n",
      "=== epoch:298, train acc:0.6666666666666666, test acc:0.5115 ===\n",
      "train loss:1.1802360376224825\n",
      "train loss:1.2728989362761567\n",
      "train loss:1.0353421757938088\n",
      "=== epoch:299, train acc:0.6633333333333333, test acc:0.5132 ===\n",
      "train loss:1.1736998871906903\n",
      "train loss:1.1184574090622557\n",
      "train loss:0.9454562260414242\n",
      "=== epoch:300, train acc:0.6733333333333333, test acc:0.5123 ===\n",
      "train loss:1.1338612770797771\n",
      "train loss:1.1515499199492698\n",
      "train loss:1.1021974837757909\n",
      "=== epoch:301, train acc:0.68, test acc:0.5127 ===\n",
      "train loss:1.004291489502032\n",
      "train loss:1.1406161942397202\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.511\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "#from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# Dropout \n",
    "use_dropout = True  # Dropout활성화\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃을 적용하니 훈련 데이터와 시험 데이터에 대한 정확도 차이가 줄었다.\n",
    "# 또, 훈련 데이터에 대한 정확도가 100%에 도달하지도 않았다(오버피팅 억제)\n",
    "# 이처럼 드롭아웃을 이용하면 표현력을 높이면서도 오버피팅을 억제할 수 있다.\n",
    "\n",
    "# 기계학습에서는 앙상블 학습ensemble learning을 사용한다.\n",
    "# 앙상블 학습은 개별적으로 학습시킨 서로 다른 여러 모델의 출력을 평균내어 추론하는 방식이다.\n",
    "# 드롭아웃은 각 뉴런을 무작위로 삭제하는 행위를 통해 매번 다른 모델을 만들어 학습시키는 것으로 볼 수 있다.\n",
    "# 그리고 추론 때는 뉴런의 출력에 삭제한 비율을 곱함으로써, 앙상블 학습에서 여러 모델의 출력 평균을 내는 것과 같은 효과를 얻는다.\n",
    "# 따라서 드롭아웃은, 하나의 네트워크에서 앙상블 학습과 같은 효과를 구현했다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
